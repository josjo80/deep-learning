{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Deep Q-learning\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-10 14:40:17,053] Making new env: Ablation-v0\n"
     ]
    }
   ],
   "source": [
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('Ablation-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.00000000e+00   3.70000000e+01   2.13854551e-11   9.97723718e+01\n",
      "   1.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.70000000e+01   4.27709102e-11   9.97723718e+01\n",
      "   2.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.70000000e+01   6.41563653e-11   9.97723718e+01\n",
      "   3.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.70000000e+01   8.55418204e-11   9.97723718e+01\n",
      "   4.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.70000000e+01   1.06927276e-10   9.97723718e+01\n",
      "   5.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+00   3.73556090e+01   1.28312731e-10   9.91770617e+01\n",
      "   6.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.73556090e+01   1.54198189e-10   9.91770617e+01\n",
      "   7.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+00   3.77112180e+01   1.80083647e-10   9.85877222e+01\n",
      "   8.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.77112180e+01   2.11402329e-10   9.85877222e+01\n",
      "   9.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.77112180e+01   2.42721010e-10   9.85877222e+01\n",
      "   1.00000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   3.77112180e+01   2.74039691e-10   9.85877222e+01\n",
      "   1.10000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   3.80668269e+01   3.05358373e-10   9.80042670e+01\n",
      "   1.20000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   3.84224359e+01   3.43234187e-10   9.74266114e+01\n",
      "   1.30000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   3.91336539e+01   3.89020116e-10   9.62883680e+01\n",
      "   1.40000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   4.02004808e+01   4.55840559e-10   9.46224723e+01\n",
      "   1.50000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.09116988e+01   5.73270258e-10   9.35386221e+01\n",
      "   1.60000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.16229168e+01   7.43917576e-10   9.24754799e+01\n",
      "   1.70000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.23341347e+01   9.91481565e-10   9.14324784e+01\n",
      "   1.80000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.30453527e+01   1.35002924e-09   9.04090707e+01\n",
      "   1.90000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.37565707e+01   1.86845040e-09   8.94047297e+01\n",
      "   2.00000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.41121797e+01   2.61679177e-09   8.89095494e+01\n",
      "   2.10000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.44677886e+01   3.51533761e-09   8.84189464e+01\n",
      "   2.20000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.44677886e+01   4.59379463e-09   8.84189464e+01\n",
      "   2.30000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.44677886e+01   5.67225166e-09   8.84189463e+01\n",
      "   2.40000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.44677887e+01   6.75070869e-09   8.84189463e+01\n",
      "   2.50000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.48233976e+01   7.82916572e-09   8.79328597e+01\n",
      "   2.60000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.48233977e+01   9.12302833e-09   8.79328597e+01\n",
      "   2.70000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.51790066e+01   1.04168909e-08   8.74512298e+01\n",
      "   2.80000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.51790067e+01   1.19685517e-08   8.74512298e+01\n",
      "   2.90000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.51790067e+01   1.35202126e-08   8.74512298e+01\n",
      "   3.00000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.51790067e+01   1.50718734e-08   8.74512297e+01\n",
      "   3.10000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.55346157e+01   1.66235342e-08   8.69739978e+01\n",
      "   3.20000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.55346157e+01   1.84836043e-08   8.69739977e+01\n",
      "   3.30000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.55346157e+01   2.03436745e-08   8.69739977e+01\n",
      "   3.40000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.55346157e+01   2.22037446e-08   8.69739977e+01\n",
      "   3.50000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.55346158e+01   2.40638148e-08   8.69739976e+01\n",
      "   3.60000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.55346158e+01   2.59238850e-08   8.69739976e+01\n",
      "   3.70000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.58902248e+01   2.77839553e-08   8.65011059e+01\n",
      "   3.80000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.58902248e+01   3.00128335e-08   8.65011058e+01\n",
      "   3.90000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.62458338e+01   3.22417118e-08   8.60324976e+01\n",
      "   4.00000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.69570518e+01   3.49114486e-08   8.51079098e+01\n",
      "   4.10000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.73126609e+01   3.87371419e-08   8.46518216e+01\n",
      "   4.20000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.80238789e+01   4.33140368e-08   8.37517918e+01\n",
      "   4.30000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.83794879e+01   4.98570120e-08   8.33077470e+01\n",
      "   4.40000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.83794880e+01   5.76754492e-08   8.33077469e+01\n",
      "   4.50000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.83794880e+01   6.54938867e-08   8.33077469e+01\n",
      "   4.60000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.83794881e+01   7.33123245e-08   8.33077468e+01\n",
      "   4.70000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.83794882e+01   8.11307625e-08   8.33077467e+01\n",
      "   4.80000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.87350973e+01   8.89492009e-08   8.28676146e+01\n",
      "   4.90000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.87350974e+01   9.82880598e-08   8.28676145e+01\n",
      "   5.00000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.87350975e+01   1.07626919e-07   8.28676143e+01\n",
      "   5.10000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.87350976e+01   1.16965779e-07   8.28676142e+01\n",
      "   5.20000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.87350977e+01   1.26304640e-07   8.28676140e+01\n",
      "   5.30000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.87350978e+01   1.35643501e-07   8.28676139e+01\n",
      "   5.40000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.90907070e+01   1.44982362e-07   8.24313449e+01\n",
      "   5.50000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.98019251e+01   1.56132941e-07   8.15702033e+01\n",
      "   5.60000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   5.01575342e+01   1.72010935e-07   8.11452355e+01\n",
      "   5.70000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   5.05131434e+01   1.90947076e-07   8.07239410e+01\n",
      "   5.80000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   5.08687526e+01   2.13521634e-07   8.03062745e+01\n",
      "   5.90000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   5.12243618e+01   2.40423319e-07   7.98921911e+01\n",
      "   6.00000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   5.15799711e+01   2.72469241e-07   7.94816467e+01\n",
      "   6.10000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   5.22911894e+01   3.10628469e-07   7.86710027e+01\n",
      "   6.20000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   5.33580167e+01   3.64673536e-07   7.74805187e+01\n",
      "   6.30000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   5.47804531e+01   4.55509123e-07   7.59390790e+01\n",
      "   6.40000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   5.58472806e+01   6.36076935e-07   7.48160573e+01\n",
      "   6.50000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   5.72697175e+01   9.37194023e-07   7.33609037e+01\n",
      "   6.60000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   5.86921550e+01   1.52961613e-06   7.19519730e+01\n",
      "   6.70000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   5.97589846e+01   2.68841397e-06   7.09243536e+01\n",
      "   6.80000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   6.08258161e+01   4.59785507e-06   6.99207315e+01\n",
      "   6.90000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   6.22482598e+01   7.73416915e-06   6.86185306e+01\n",
      "   7.00000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   6.33151005e+01   1.37825376e-05   6.76678668e+01\n",
      "   7.10000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   6.40263421e+01   2.36446791e-05   6.70460550e+01\n",
      "   7.20000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   6.50932064e+01   3.72836920e-05   6.61307886e+01\n",
      "   7.30000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   6.58044837e+01   5.94090606e-05   6.55319289e+01\n",
      "   7.40000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.61601826e+01   8.99044502e-05   6.52357816e+01\n",
      "   7.50000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.61603083e+01   1.25689258e-04   6.52356781e+01\n",
      "   7.60000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.61604698e+01   1.61476087e-04   6.52355452e+01\n",
      "   7.70000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.61606671e+01   1.97265512e-04   6.52353829e+01\n",
      "   7.80000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.61609001e+01   2.33058108e-04   6.52351911e+01\n",
      "   7.90000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.65167780e+01   2.68854451e-04   6.49410931e+01\n",
      "   8.00000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.65170888e+01   3.10848933e-04   6.49408396e+01\n",
      "   8.10000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.68730506e+01   3.52849267e-04   6.46488456e+01\n",
      "   8.20000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.72290617e+01   4.02107330e-04   6.43589608e+01\n",
      "   8.30000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.75851306e+01   4.59859282e-04   6.40711569e+01\n",
      "   8.40000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.79412671e+01   5.27549016e-04   6.37854053e+01\n",
      "   8.50000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.79418740e+01   6.06862687e-04   6.37849291e+01\n",
      "   8.60000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.79425602e+01   6.86197756e-04   6.37843908e+01\n",
      "   8.70000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.79433257e+01   7.65557029e-04   6.37837903e+01\n",
      "   8.80000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.79441707e+01   8.44943312e-04   6.37831276e+01\n",
      "   8.90000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.79450950e+01   9.24359418e-04   6.37824028e+01\n",
      "   9.00000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.79460988e+01   1.00380816e-03   6.37816157e+01\n",
      "   9.10000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.83027911e+01   1.08329236e-03   6.34975446e+01\n",
      "   9.20000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.83039675e+01   1.17641765e-03   6.34966321e+01\n",
      "   9.30000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.83052371e+01   1.26959154e-03   6.34956475e+01\n",
      "   9.40000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.86622089e+01   1.36281792e-03   6.32134463e+01\n",
      "   9.50000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.86636809e+01   1.47202097e-03   6.32123177e+01\n",
      "   9.60000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.90208712e+01   1.58129520e-03   6.29320127e+01\n",
      "   9.70000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.90225805e+01   1.70926625e-03   6.29307182e+01\n",
      "   9.80000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.90244178e+01   1.83733396e-03   6.29293269e+01\n",
      "   9.90000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.93819923e+01   1.96550564e-03   6.26507899e+01\n",
      "   1.00000000e+02] -1.0 False {}\n",
      "[  1.00000000e+01   7.00953258e+01   2.11558298e-03   6.21010902e+01\n",
      "   1.01000000e+02] -1.0 False {}\n",
      "[  1.00000000e+01   7.08088648e+01   2.32097653e-03   6.15591178e+01\n",
      "   1.02000000e+02] -1.0 False {}\n",
      "[  5.00000000e+00   7.11670755e+01   2.60173460e-03   6.12900414e+01\n",
      "   1.03000000e+02] -1.0 False {}\n",
      "[  5.00000000e+00   7.15256145e+01   2.93003169e-03   6.10226845e+01\n",
      "   1.04000000e+02] -1.0 False {}\n",
      "[  5.00000000e+00   7.18845373e+01   3.31384735e-03   6.07570066e+01\n",
      "   1.05000000e+02] -1.0 False {}\n",
      "[  0.00000000e+00   7.18882998e+01   3.76249948e-03   6.07545465e+01\n",
      "   1.06000000e+02] -1.0 False {}\n",
      "[  5.00000000e+00   7.22481207e+01   4.21188552e-03   6.04902378e+01\n",
      "   1.07000000e+02] -1.0 False {}\n",
      "[  1.00000000e+01   7.29640759e+01   4.73721689e-03   5.99696560e+01\n",
      "   1.08000000e+02] -1.0 False {}\n",
      "[  1.50000000e+01   7.40363561e+01   5.45327236e-03   5.92036031e+01\n",
      "   1.09000000e+02] -1.0 False {}\n",
      "[  2.00000000e+01   7.54653813e+01   6.58924674e-03   5.82076754e+01\n",
      "   1.10000000e+02] -1.0 False {}\n",
      "[  2.00000000e+01   7.68964984e+01   8.68120887e-03   5.72392780e+01\n",
      "   1.11000000e+02] -1.0 False {}\n",
      "[  2.50000000e+01   7.86870612e+01   1.25179047e-02   5.60684901e+01\n",
      "   1.12000000e+02] -1.0 False {}\n",
      "[  3.00000000e+01   8.08413707e+01   2.06555886e-02   5.47286004e+01\n",
      "   1.13000000e+02] -1.0 False {}\n",
      "[  3.50000000e+01   8.33711960e+01   4.05624225e-02   5.33131949e+01\n",
      "   1.14000000e+02] -1.0 False {}\n",
      "[  4.00000000e+01   8.63127647e+01   9.66967952e-02   5.23825352e+01\n",
      "   1.15000000e+02] -1.0 False {}\n",
      "[  45.           89.79391959    0.28067409   57.42327937  116.        ] -1.0 False {}\n",
      "[  40.           93.65072291    1.01193146  149.96805636  117.        ] -1 True {}\n",
      "[  5.00000000e+00   3.72587164e+01   2.13854551e-11   6.95594483e+01\n",
      "   1.00000000e+00] -1.0 False {}\n",
      "[  1.00000000e+01   3.77761493e+01   4.59595088e-11   6.89587121e+01\n",
      "   2.00000000e+00] -1.0 False {}\n",
      "[  1.50000000e+01   3.85522986e+01   7.83854114e-11   6.80738646e+01\n",
      "   3.00000000e+00] -1.0 False {}\n",
      "[  1.50000000e+01   3.93284478e+01   1.27449687e-10   6.72079870e+01\n",
      "   4.00000000e+00] -1.0 False {}\n",
      "[  2.00000000e+01   4.03633135e+01   2.01537221e-10   6.60819879e+01\n",
      "   5.00000000e+00] -1.0 False {}\n",
      "[  2.00000000e+01   4.13981792e+01   3.29477212e-10   6.49873615e+01\n",
      "   6.00000000e+00] -1.0 False {}\n",
      "[  1.50000000e+01   4.21743285e+01   5.49620932e-10   6.41862265e+01\n",
      "   7.00000000e+00] -1.0 False {}\n",
      "[  2.00000000e+01   4.32091942e+01   8.79584517e-10   6.31435374e+01\n",
      "   8.00000000e+00] -1.0 False {}\n",
      "[  2.50000000e+01   4.45027764e+01   1.44383348e-09   6.18795538e+01\n",
      "   9.00000000e+00] -1.0 False {}\n",
      "[  2.00000000e+01   4.55376421e+01   2.54180672e-09   6.08985614e+01\n",
      "   1.00000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   4.68312242e+01   4.40474562e-09   5.97084022e+01\n",
      "   1.10000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   4.78660899e+01   7.99494581e-09   5.87839737e+01\n",
      "   1.20000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   4.86422392e+01   1.40400168e-08   5.81062128e+01\n",
      "   1.30000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   4.96771049e+01   2.29557762e-08   5.72225839e+01\n",
      "   1.40000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   5.04532542e+01   3.78804662e-08   5.65744477e+01\n",
      "   1.50000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   5.14881200e+01   5.97972296e-08   5.57290751e+01\n",
      "   1.60000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   5.27817022e+01   9.62751461e-08   5.47015211e+01\n",
      "   1.70000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   5.43340010e+01   1.64922096e-07   5.35093718e+01\n",
      "   1.80000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   5.56275834e+01   3.10557592e-07   5.25484540e+01\n",
      "   1.90000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   5.66624497e+01   5.81649204e-07   5.18001170e+01\n",
      "   2.00000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   5.74386000e+01   1.02573934e-06   5.12503626e+01\n",
      "   2.10000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   5.82147509e+01   1.66747599e-06   5.07101900e+01\n",
      "   2.20000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   5.92496192e+01   2.59322590e-06   5.00044556e+01\n",
      "   2.30000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   6.00257726e+01   4.09816934e-06   4.94857288e+01\n",
      "   2.40000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   6.08019281e+01   6.26054023e-06   4.89758201e+01\n",
      "   2.50000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   6.18368032e+01   9.36230562e-06   4.83092928e+01\n",
      "   2.60000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   6.31303997e+01   1.43670830e-05   4.74969090e+01\n",
      "   2.70000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   6.46827217e+01   2.34308079e-05   4.65513270e+01\n",
      "   2.80000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   6.62350621e+01   4.18049463e-05   4.56362851e+01\n",
      "   2.90000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   6.75287230e+01   7.88136063e-05   4.48960572e+01\n",
      "   3.00000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   6.85637335e+01   1.44823427e-04   4.43178979e+01\n",
      "   3.10000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   6.93401322e+01   2.49367263e-04   4.38921662e+01\n",
      "   3.20000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   6.98579617e+01   3.96700503e-04   4.36119354e+01\n",
      "   3.30000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   7.06346928e+01   5.81757226e-04   4.31970565e+01\n",
      "   3.40000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   7.16704004e+01   8.41922488e-04   4.26538241e+01\n",
      "   3.50000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   7.24478004e+01   1.25069745e-03   4.22534312e+01\n",
      "   3.60000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   7.29670567e+01   1.82350021e-03   4.19895222e+01\n",
      "   3.70000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.32283136e+01   2.54047773e-03   4.18579820e+01\n",
      "   3.80000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.34903730e+01   3.34298882e-03   4.17268740e+01\n",
      "   3.90000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   7.40120473e+01   4.24139510e-03   4.14676240e+01\n",
      "   4.00000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.42761293e+01   5.36558233e-03   4.13381275e+01\n",
      "   4.10000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.42827538e+01   6.62455336e-03   4.13363702e+01\n",
      "   4.20000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.42906409e+01   7.88710279e-03   4.13343133e+01\n",
      "   4.30000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.42997949e+01   9.15392572e-03   4.13319593e+01\n",
      "   4.40000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.45689370e+01   1.04257264e-02   4.12021208e+01\n",
      "   4.50000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.48395063e+01   1.18528277e-02   4.10729653e+01\n",
      "   4.60000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.51116776e+01   1.34548840e-02   4.09445996e+01\n",
      "   4.70000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.53856483e+01   1.52542496e-02   4.08171718e+01\n",
      "   4.80000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.54029247e+01   1.72764071e-02   4.08154123e+01\n",
      "   4.90000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.54222382e+01   1.93134921e-02   4.08135483e+01\n",
      "   5.00000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.54436056e+01   2.13673933e-02   4.08115993e+01\n",
      "   5.10000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.54670456e+01   2.34400587e-02   4.08095873e+01\n",
      "   5.20000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.54925791e+01   2.55335029e-02   4.08075372e+01\n",
      "   5.30000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.57789454e+01   2.76498157e-02   4.06812305e+01\n",
      "   5.40000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.60677019e+01   3.00401110e-02   4.05570749e+01\n",
      "   5.50000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.61004440e+01   3.27420574e-02   4.05584449e+01\n",
      "   5.60000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.61359257e+01   3.54817787e-02   4.05602492e+01\n",
      "   5.70000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.61741888e+01   3.82630240e-02   4.05625615e+01\n",
      "   5.80000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.64739949e+01   4.10897439e-02   4.04428650e+01\n",
      "   5.90000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.67770105e+01   4.42991010e-02   4.03274462e+01\n",
      "   6.00000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.70836739e+01   4.79470395e-02   4.02173926e+01\n",
      "   6.10000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.73944893e+01   5.20989567e-02   4.01141341e+01\n",
      "   6.20000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.74513210e+01   5.68316725e-02   4.01393045e+01\n",
      "   6.30000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.75129999e+01   6.16789349e-02   4.01681483e+01\n",
      "   6.40000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.75796535e+01   6.66536093e-02   4.02011189e+01\n",
      "   6.50000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.76514232e+01   7.17696875e-02   4.02387407e+01\n",
      "   6.60000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.79871821e+01   7.70424574e-02   4.01625003e+01\n",
      "   6.70000000e+01] -1.0 False {}\n",
      "[  5.          78.32901198   0.08311347  40.10323317  68.        ] -1.0 False {}\n",
      "[  5.          78.67784787   0.09011946  40.06593035  69.        ] -1.0 False {}\n",
      "[  0.          78.77607375   0.09822588  40.17411992  70.        ] -1.0 False {}\n",
      "[  0.          78.88274556   0.10667181  40.29895121  71.        ] -1.0 False {}\n",
      "[  0.          78.99824789   0.11550233  40.44303536  72.        ] -1.0 False {}\n",
      "[  5.          79.38173308   0.12476877  40.49348372  73.        ] -1.0 False {}\n",
      "[  0.          79.51737347   0.13564039  40.71597878  74.        ] -1.0 False {}\n",
      "[  5.          79.92323296   0.14714307  40.86080708  75.        ] -1.0 False {}\n",
      "[ 10.          80.60142357   0.16075776  40.98149801  76.        ] -1.0 False {}\n",
      "[ 10.          81.29764291   0.17878648  41.29108381  77.        ] -1.0 False {}\n",
      "[ 10.          82.0178881    0.20281234  41.89895112  78.        ] -1.0 False {}\n",
      "[ 10.          82.77043176   0.2351108   42.9948865   79.        ] -1.0 False {}\n",
      "[ 15.          83.82563505   0.27905402  44.81499076  80.        ] -1.0 False {}\n",
      "[ 10.          84.68964126   0.34657335  48.6856666   81.        ] -1.0 False {}\n",
      "[  5.          85.39072672   0.44236903  55.96053773  82.        ] -1.0 False {}\n",
      "[  5.          86.21889279   0.56944965  68.48919074  83.        ] -1.0 False {}\n",
      "[  0.          86.96553387   0.74664109  91.51615952  84.        ] -1.0 False {}\n",
      "[   5.           88.20968671    0.9854364   132.39755213   85.        ] -1 True {}\n",
      "[  1.00000000e+01   3.75402494e+01   2.13854551e-11   7.66092698e+01\n",
      "   1.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+00   3.78103742e+01   4.99642548e-11   7.62637842e+01\n",
      "   2.00000000e+00] -1.0 False {}\n",
      "[  1.00000000e+01   3.83506236e+01   8.29892411e-11   7.55806446e+01\n",
      "   3.00000000e+00] -1.0 False {}\n",
      "[  1.50000000e+01   3.91609978e+01   1.27056215e-10   7.45750908e+01\n",
      "   4.00000000e+00] -1.0 False {}\n",
      "[  2.00000000e+01   4.02414966e+01   1.94852589e-10   7.32689637e+01\n",
      "   5.00000000e+00] -1.0 False {}\n",
      "[  2.00000000e+01   4.13219955e+01   3.14846446e-10   7.20008651e+01\n",
      "   6.00000000e+00] -1.0 False {}\n",
      "[  2.00000000e+01   4.24024944e+01   5.26393833e-10   7.07692143e+01\n",
      "   7.00000000e+00] -1.0 False {}\n",
      "[  1.50000000e+01   4.32128685e+01   8.97903341e-10   6.98684928e+01\n",
      "   8.00000000e+00] -1.0 False {}\n",
      "[  1.00000000e+01   4.37531180e+01   1.46322463e-09   6.92786359e+01\n",
      "   9.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+00   4.40232427e+01   2.21023661e-09   6.89868297e+01\n",
      "   1.00000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.45634921e+01   3.06863535e-09   6.84093565e+01\n",
      "   1.10000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   4.53738663e+01   4.20130729e-09   6.75581869e+01\n",
      "   1.20000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   4.61842405e+01   5.91511015e-09   6.67245876e+01\n",
      "   1.30000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   4.69946146e+01   8.50275544e-09   6.59080402e+01\n",
      "   1.40000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.75348641e+01   1.24016610e-08   6.53729017e+01\n",
      "   1.50000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.78049888e+01   1.75200677e-08   6.51080464e+01\n",
      "   1.60000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.83452383e+01   2.33825512e-08   6.45836760e+01\n",
      "   1.70000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.88854877e+01   3.10681575e-08   6.40663119e+01\n",
      "   1.80000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.94257372e+01   4.11346940e-08   6.35558199e+01\n",
      "   1.90000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   5.02361114e+01   5.43078379e-08   6.28026822e+01\n",
      "   2.00000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   5.07763609e+01   7.39944822e-08   6.23088058e+01\n",
      "   2.10000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   5.13166105e+01   9.96989255e-08   6.18213583e+01\n",
      "   2.20000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   5.18568600e+01   1.33230888e-07   6.13402199e+01\n",
      "   2.30000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   5.23971097e+01   1.76935365e-07   6.08652737e+01\n",
      "   2.40000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   5.29373593e+01   2.33848299e-07   6.03964058e+01\n",
      "   2.50000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   5.34776091e+01   3.07896760e-07   5.99335050e+01\n",
      "   2.60000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   5.42879836e+01   4.04156121e-07   5.92501057e+01\n",
      "   2.70000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   5.53684831e+01   5.46594980e-07   5.83588001e+01\n",
      "   2.80000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   5.67191074e+01   7.86056888e-07   5.72755101e+01\n",
      "   2.90000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   5.77996076e+01   1.24227024e-06   5.64326171e+01\n",
      "   3.00000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   5.88801084e+01   2.00341680e-06   5.56100353e+01\n",
      "   3.10000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   6.02307353e+01   3.26909092e-06   5.46093158e+01\n",
      "   3.20000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   6.15813645e+01   5.64798937e-06   5.36379601e+01\n",
      "   3.30000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   6.29319982e+01   1.00965425e-05   5.26947484e+01\n",
      "   3.40000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   6.42826402e+01   1.83736314e-05   5.17785256e+01\n",
      "   3.50000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   6.56332975e+01   3.36978864e-05   5.08881961e+01\n",
      "   3.60000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   6.67138583e+01   6.19305073e-05   5.01938644e+01\n",
      "   3.70000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   6.80645897e+01   1.07801360e-04   4.93475473e+01\n",
      "   3.80000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   6.96855296e+01   1.91582698e-04   4.83624008e+01\n",
      "   3.90000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   7.10365163e+01   3.63124783e-04   4.75656857e+01\n",
      "   4.00000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   7.23878131e+01   6.73239813e-04   4.67900636e+01\n",
      "   4.10000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   7.37396681e+01   1.23135322e-03   4.60346647e+01\n",
      "   4.20000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   7.48223984e+01   2.23144077e-03   4.54441623e+01\n",
      "   4.30000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   7.56365944e+01   3.82183405e-03   4.50089191e+01\n",
      "   4.40000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   7.61829157e+01   6.07182201e-03   4.47222663e+01\n",
      "   4.50000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   7.70021988e+01   8.90901594e-03   4.42989301e+01\n",
      "   4.60000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   7.78254937e+01   1.29206991e-02   4.38846749e+01\n",
      "   4.70000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   7.89245860e+01   1.85934452e-02   4.33479975e+01\n",
      "   4.80000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   8.00326644e+01   2.75794880e-02   4.28418519e+01\n",
      "   4.90000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   8.14251143e+01   4.18263192e-02   4.22683469e+01\n",
      "   5.00000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   8.25727592e+01   6.71460894e-02   4.20028946e+01\n",
      "   5.10000000e+01] -1.0 False {}\n",
      "[ 25.          84.03106342   0.10768058  42.03976088  52.        ] -1.0 False {}\n",
      "[ 20.          85.29262919   0.1810669   43.59170451  53.        ] -1.0 False {}\n",
      "[ 20.          86.67635666   0.30322859  48.90047474  54.        ] -1.0 False {}\n",
      "[ 20.          88.27284979   0.51599426  65.64805939  55.        ] -1.0 False {}\n",
      "[  20.           90.27078901    0.91744034  122.36477587   56.        ] -1 True {}\n",
      "[  0.00000000e+00   3.70000000e+01   2.13854551e-11   8.28933916e+01\n",
      "   1.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.70000000e+01   4.27709102e-11   8.28933916e+01\n",
      "   2.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.70000000e+01   6.41563653e-11   8.28933916e+01\n",
      "   3.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.70000000e+01   8.55418204e-11   8.28933916e+01\n",
      "   4.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.70000000e+01   1.06927276e-10   8.28933916e+01\n",
      "   5.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.70000000e+01   1.28312731e-10   8.28933916e+01\n",
      "   6.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.70000000e+01   1.49698186e-10   8.28933916e+01\n",
      "   7.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.70000000e+01   1.71083641e-10   8.28933916e+01\n",
      "   8.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+00   3.72849853e+01   1.92469096e-10   8.24966228e+01\n",
      "   9.00000000e+00] -1.0 False {}\n",
      "[  1.00000000e+01   3.78549560e+01   2.17392060e-10   8.17126335e+01\n",
      "   1.00000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   3.84249266e+01   2.51213847e-10   8.09411303e+01\n",
      "   1.10000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   3.89948973e+01   2.97060570e-10   8.01818274e+01\n",
      "   1.20000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   3.95648680e+01   3.59138549e-10   7.94344474e+01\n",
      "   1.30000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   4.04198240e+01   4.43101368e-10   7.83351464e+01\n",
      "   1.40000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   4.12747799e+01   5.74901920e-10   7.72611937e+01\n",
      "   1.50000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   4.21297359e+01   7.81288984e-10   7.62117527e+01\n",
      "   1.60000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.26997066e+01   1.10368630e-09   7.55253463e+01\n",
      "   1.70000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.32696773e+01   1.53714538e-09   7.48492487e+01\n",
      "   1.80000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   4.41246332e+01   2.11930443e-09   7.38539475e+01\n",
      "   1.90000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   4.49795892e+01   3.02361801e-09   7.28806195e+01\n",
      "   2.00000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   4.58345452e+01   4.42503816e-09   7.19285714e+01\n",
      "   2.10000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.64045159e+01   6.59173342e-09   7.13053654e+01\n",
      "   2.20000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.66895012e+01   9.48499890e-09   7.09971384e+01\n",
      "   2.30000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.69744866e+01   1.28270698e-08   7.06911309e+01\n",
      "   2.40000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.72594719e+01   1.66865741e-08   7.03873199e+01\n",
      "   2.50000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.78294426e+01   2.11424817e-08   6.97861974e+01\n",
      "   2.60000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.83994133e+01   2.70773770e-08   6.91935931e+01\n",
      "   2.70000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   4.92543693e+01   3.49741317e-08   6.83202817e+01\n",
      "   2.80000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   5.03943107e+01   4.70711888e-08   6.71841056e+01\n",
      "   2.90000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   5.15342521e+01   6.83590348e-08   6.60790367e+01\n",
      "   3.00000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   5.29591788e+01   1.05672036e-07   6.47396066e+01\n",
      "   3.10000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   5.46690910e+01   1.80510455e-07   6.31908267e+01\n",
      "   3.20000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   5.60940180e+01   3.51659055e-07   6.19465167e+01\n",
      "   3.30000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   5.75189453e+01   6.90422791e-07   6.07422575e+01\n",
      "   3.40000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   5.89438733e+01   1.35702227e-06   5.95762250e+01\n",
      "   3.50000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   6.03688026e+01   2.66112105e-06   5.84467024e+01\n",
      "   3.60000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   6.20787198e+01   5.19780242e-06   5.71371996e+01\n",
      "   3.70000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   6.37886426e+01   1.07924184e-05   5.58753293e+01\n",
      "   3.80000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   6.54985776e+01   2.30326401e-05   5.46586463e+01\n",
      "   3.90000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   6.72085391e+01   4.96017494e-05   5.34848631e+01\n",
      "   4.00000000e+01] -1.0 False {}\n",
      "[  3.50000000e+01   6.92035433e+01   1.06827023e-04   5.21668283e+01\n",
      "   4.10000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   7.09137008e+01   2.45546139e-04   5.10787924e+01\n",
      "   4.20000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   7.26241522e+01   5.39466096e-04   5.00272329e+01\n",
      "   4.30000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   7.40502366e+01   1.15769801e-03   4.91773439e+01\n",
      "   4.40000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   7.54774637e+01   2.30045753e-03   4.83504118e+01\n",
      "   4.50000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   7.69067935e+01   4.40320292e-03   4.75457795e+01\n",
      "   4.60000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   7.86249621e+01   8.25660593e-03   4.66103258e+01\n",
      "   4.70000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   8.00660746e+01   1.61858447e-02   4.58641070e+01\n",
      "   4.80000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   8.18066180e+01   3.06313786e-02   4.50339706e+01\n",
      "   4.90000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   8.32917931e+01   6.02484433e-02   4.45594298e+01\n",
      "   5.00000000e+01] -1.0 False {}\n",
      "[ 30.          85.11630289   0.11459786  44.62305602  51.        ] -1.0 False {}\n",
      "[ 25.          86.7696151    0.22838557  47.74694725  52.        ] -1.0 False {}\n",
      "[ 30.          88.92875136   0.44922428  61.72769132  53.        ] -1.0 False {}\n",
      "[  25.           91.32313948    0.96946147  134.48463856   54.        ] -1 True {}\n",
      "[  0.00000000e+00   3.70000000e+01   2.13854551e-11   7.60231139e+01\n",
      "   1.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.70000000e+01   4.27709102e-11   7.60231139e+01\n",
      "   2.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.70000000e+01   6.41563653e-11   7.60231139e+01\n",
      "   3.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.70000000e+01   8.55418204e-11   7.60231139e+01\n",
      "   4.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+00   3.73018413e+01   1.06927276e-10   7.56377992e+01\n",
      "   5.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.73018413e+01   1.32076698e-10   7.56377992e+01\n",
      "   6.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.73018413e+01   1.57226120e-10   7.56377992e+01\n",
      "   7.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.73018413e+01   1.82375543e-10   7.56377992e+01\n",
      "   8.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+00   3.76036826e+01   2.07524965e-10   7.52557694e+01\n",
      "   9.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+00   3.79055239e+01   2.37091522e-10   7.48769841e+01\n",
      "   1.00000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   3.79055239e+01   2.71840105e-10   7.48769841e+01\n",
      "   1.10000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   3.79055239e+01   3.06588689e-10   7.48769841e+01\n",
      "   1.20000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   3.79055239e+01   3.41337272e-10   7.48769841e+01\n",
      "   1.30000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   3.79055239e+01   3.76085856e-10   7.48769841e+01\n",
      "   1.40000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   3.79055239e+01   4.10834440e-10   7.48769841e+01\n",
      "   1.50000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   3.79055239e+01   4.45583023e-10   7.48769841e+01\n",
      "   1.60000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   3.79055239e+01   4.80331607e-10   7.48769841e+01\n",
      "   1.70000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   3.82073652e+01   5.15080190e-10   7.45014036e+01\n",
      "   1.80000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   3.88110478e+01   5.55906251e-10   7.37597009e+01\n",
      "   1.90000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   3.97165717e+01   6.12209290e-10   7.26702247e+01\n",
      "   2.00000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.03202543e+01   7.03182457e-10   7.19588645e+01\n",
      "   2.10000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.06220956e+01   8.28256003e-10   7.16075650e+01\n",
      "   2.20000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.12257782e+01   9.74841851e-10   7.09135550e+01\n",
      "   2.30000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.15276195e+01   1.17600487e-09   7.05707773e+01\n",
      "   2.40000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.21313021e+01   1.41155232e-09   6.98935122e+01\n",
      "   2.50000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   4.30368260e+01   1.73421244e-09   6.88978628e+01\n",
      "   2.60000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.36405086e+01   2.25035200e-09   6.82472350e+01\n",
      "   2.70000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.42441912e+01   2.95526208e-09   6.76068395e+01\n",
      "   2.80000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.48478738e+01   3.91684196e-09   6.69764456e+01\n",
      "   2.90000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.54515564e+01   5.22700400e-09   6.63558294e+01\n",
      "   3.00000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.57533977e+01   7.01002135e-09   6.60491198e+01\n",
      "   3.10000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.57533977e+01   9.08914752e-09   6.60491197e+01\n",
      "   3.20000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.57533978e+01   1.11682737e-08   6.60491197e+01\n",
      "   3.30000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.57533978e+01   1.32473999e-08   6.60491197e+01\n",
      "   3.40000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.57533978e+01   1.53265261e-08   6.60491197e+01\n",
      "   3.50000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.57533978e+01   1.74056523e-08   6.60491197e+01\n",
      "   3.60000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.60552391e+01   1.94847785e-08   6.57447735e+01\n",
      "   3.70000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.66589217e+01   2.19084845e-08   6.51430670e+01\n",
      "   3.80000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.69607631e+01   2.51992806e-08   6.48456555e+01\n",
      "   3.90000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.75644457e+01   2.90321464e-08   6.42575908e+01\n",
      "   4.00000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.81681283e+01   3.42272590e-08   6.36783742e+01\n",
      "   4.10000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.87718110e+01   4.12607357e-08   6.31078151e+01\n",
      "   4.20000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   4.96773349e+01   5.07722939e-08   6.22678059e+01\n",
      "   4.30000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   5.05828589e+01   6.56986873e-08   6.14462575e+01\n",
      "   4.40000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   5.17902242e+01   8.90635532e-08   6.03785802e+01\n",
      "   4.50000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   5.32994308e+01   1.31364875e-07   5.90867108e+01\n",
      "   4.60000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   5.48086375e+01   2.19654714e-07   5.78400850e+01\n",
      "   4.70000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   5.66196857e+01   4.02686468e-07   5.64007091e+01\n",
      "   4.80000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   5.81288931e+01   8.37837434e-07   5.52459295e+01\n",
      "   4.90000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   5.93362600e+01   1.72688836e-06   5.43499578e+01\n",
      "   5.00000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   6.08454698e+01   3.29410144e-06   5.32632708e+01\n",
      "   5.10000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   6.23546828e+01   6.45912479e-06   5.22119487e+01\n",
      "   5.20000000e+01] -1.0 False {}\n",
      "[  2.50000000e+01   6.38639021e+01   1.28106818e-05   5.11943646e+01\n",
      "   5.30000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   6.56749754e+01   2.54777295e-05   5.00156523e+01\n",
      "   5.40000000e+01] -1.0 False {}\n",
      "[  3.50000000e+01   6.77879187e+01   5.42455029e-05   4.86958228e+01\n",
      "   5.50000000e+01] -1.0 False {}\n",
      "[  3.50000000e+01   6.99009361e+01   1.28330505e-04   4.74321097e+01\n",
      "   5.60000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   7.17123009e+01   3.16915762e-04   4.63909723e+01\n",
      "   5.70000000e+01] -1.0 False {}\n",
      "[  3.50000000e+01   7.38259232e+01   7.33208021e-04   4.52225910e+01\n",
      "   5.80000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   7.56387420e+01   1.77105620e-03   4.42584847e+01\n",
      "   5.90000000e+01] -1.0 False {}\n",
      "[  3.50000000e+01   7.77556542e+01   4.02309933e-03   4.31754116e+01\n",
      "   6.00000000e+01] -1.0 False {}\n",
      "[  3.00000000e+01   7.95762339e+01   9.53189648e-03   4.22844533e+01\n",
      "   6.10000000e+01] -1.0 False {}\n",
      "[  3.50000000e+01   8.17104425e+01   2.13195279e-02   4.13057255e+01\n",
      "   6.20000000e+01] -1.0 False {}\n",
      "[  3.50000000e+01   8.38731215e+01   4.97898627e-02   4.05193046e+01\n",
      "   6.30000000e+01] -1.0 False {}\n",
      "[ 40.          86.40647479   0.11862287  40.56818365  64.        ] -1.0 False {}\n",
      "[ 40.          89.13083498   0.30962979  47.60832422  65.        ] -1.0 False {}\n",
      "[  35.           92.11673644    0.87301237  113.04749051   66.        ] -1 True {}\n",
      "[  5.00000000e+00   3.74465839e+01   2.13854551e-11   1.11000372e+02\n",
      "   1.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+00   3.78931677e+01   4.85650565e-11   1.10173956e+02\n",
      "   2.00000000e+00] -1.0 False {}\n",
      "[  1.00000000e+01   3.87863354e+01   8.30848884e-11   1.08551913e+02\n",
      "   3.00000000e+00] -1.0 False {}\n",
      "[  1.50000000e+01   4.01260870e+01   1.38653302e-10   1.06193104e+02\n",
      "   4.00000000e+00] -1.0 False {}\n",
      "[  1.00000000e+01   4.10192547e+01   2.51569548e-10   1.04668049e+02\n",
      "   5.00000000e+00] -1.0 False {}\n",
      "[  1.00000000e+01   4.19124224e+01   4.32113527e-10   1.03179450e+02\n",
      "   6.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+00   4.23590063e+01   7.20021662e-10   1.02448430e+02\n",
      "   7.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   4.23590063e+01   1.08323275e-09   1.02448430e+02\n",
      "   8.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   4.23590063e+01   1.44644384e-09   1.02448430e+02\n",
      "   9.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+00   4.28055901e+01   1.80965492e-09   1.01726060e+02\n",
      "   1.00000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.28055901e+01   2.26756375e-09   1.01726060e+02\n",
      "   1.10000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.28055901e+01   2.72547257e-09   1.01726060e+02\n",
      "   1.20000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.28055901e+01   3.18338140e-09   1.01726060e+02\n",
      "   1.30000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.32521740e+01   3.64129022e-09   1.01012194e+02\n",
      "   1.40000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.36987578e+01   4.21820929e-09   1.00306688e+02\n",
      "   1.50000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.36987578e+01   4.94459606e-09   1.00306688e+02\n",
      "   1.60000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.36987578e+01   5.67098284e-09   1.00306688e+02\n",
      "   1.70000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.41453417e+01   6.39736962e-09   9.96094010e+01\n",
      "   1.80000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.41453417e+01   7.31135516e-09   9.96094010e+01\n",
      "   1.90000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.41453417e+01   8.22534071e-09   9.96094010e+01\n",
      "   2.00000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.41453417e+01   9.13932626e-09   9.96094010e+01\n",
      "   2.10000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.45919256e+01   1.00533118e-08   9.89201960e+01\n",
      "   2.20000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.50385095e+01   1.12026035e-08   9.82389381e+01\n",
      "   2.30000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.50385095e+01   1.26468521e-08   9.82389381e+01\n",
      "   2.40000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.50385095e+01   1.40911006e-08   9.82389381e+01\n",
      "   2.50000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.50385095e+01   1.55353492e-08   9.82389381e+01\n",
      "   2.60000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.50385095e+01   1.69795978e-08   9.82389380e+01\n",
      "   2.70000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   4.50385095e+01   1.84238464e-08   9.82389380e+01\n",
      "   2.80000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.54850934e+01   1.98680950e-08   9.75654958e+01\n",
      "   2.90000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.63782611e+01   2.16818370e-08   9.62415464e+01\n",
      "   3.00000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   4.72714289e+01   2.45368824e-08   9.49473507e+01\n",
      "   3.10000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.77180128e+01   2.90197099e-08   9.43111106e+01\n",
      "   3.20000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.81645966e+01   3.46316430e-08   9.36819543e+01\n",
      "   3.30000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.86111805e+01   4.16526878e-08   9.30597685e+01\n",
      "   3.40000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.90577644e+01   5.04312005e-08   9.24444427e+01\n",
      "   3.50000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.95043484e+01   6.14003058e-08   9.18358683e+01\n",
      "   3.60000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   4.99509323e+01   7.50981948e-08   9.12339393e+01\n",
      "   3.70000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   5.03975162e+01   9.21932055e-08   9.06385516e+01\n",
      "   3.80000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   5.12906841e+01   1.13514791e-07   8.94669953e+01\n",
      "   3.90000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   5.26304358e+01   1.46622361e-07   8.77562422e+01\n",
      "   4.00000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   5.39701875e+01   2.10393505e-07   8.60991456e+01\n",
      "   4.10000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   5.53099394e+01   3.32570409e-07   8.44933196e+01\n",
      "   4.20000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   5.66496916e+01   5.65406650e-07   8.29365163e+01\n",
      "   4.30000000e+01] -1.0 False {}\n",
      "[  2.00000000e+01   5.84360280e+01   1.00681109e-06   8.09333899e+01\n",
      "   4.40000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   5.97757816e+01   2.03417992e-06   7.94829333e+01\n",
      "   4.50000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   6.06689533e+01   3.95864560e-06   7.85396288e+01\n",
      "   4.60000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.11155440e+01   6.87484803e-06   7.80748739e+01\n",
      "   4.70000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.15621383e+01   1.04616769e-05   7.76146316e+01\n",
      "   4.80000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.15621532e+01   1.48709245e-05   7.76146164e+01\n",
      "   4.90000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.15621724e+01   1.92802024e-05   7.76145966e+01\n",
      "   5.00000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.15621961e+01   2.36895195e-05   7.76145723e+01\n",
      "   5.10000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.20088081e+01   2.80988849e-05   7.71587666e+01\n",
      "   5.20000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   6.29020093e+01   3.35163295e-05   7.62602954e+01\n",
      "   5.30000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   6.37952187e+01   4.16805318e-05   7.53789092e+01\n",
      "   5.40000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.42418565e+01   5.39574763e-05   7.49444491e+01\n",
      "   5.50000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.42419255e+01   6.90004364e-05   7.49443825e+01\n",
      "   5.60000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.42420096e+01   8.40438681e-05   7.49443014e+01\n",
      "   5.70000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.42421086e+01   9.90878743e-05   7.49442057e+01\n",
      "   5.80000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.42422228e+01   1.14132558e-04   7.49440956e+01\n",
      "   5.90000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.46889358e+01   1.29178021e-04   7.45136692e+01\n",
      "   6.00000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.51356673e+01   1.47603971e-04   7.40872737e+01\n",
      "   6.10000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.51358374e+01   1.70158061e-04   7.40871128e+01\n",
      "   6.20000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.55826140e+01   1.92713886e-04   7.36646711e+01\n",
      "   6.30000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.55828343e+01   2.20308944e-04   7.36644649e+01\n",
      "   6.40000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.60296661e+01   2.47906743e-04   7.32459162e+01\n",
      "   6.50000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.64765316e+01   2.81653109e-04   7.28312273e+01\n",
      "   6.60000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.64768545e+01   3.22896683e-04   7.28309315e+01\n",
      "   6.70000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   6.64772186e+01   3.64146229e-04   7.28305980e+01\n",
      "   6.80000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.69242079e+01   4.05402510e-04   7.24196427e+01\n",
      "   6.90000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   6.73712475e+01   4.55800598e-04   7.20124340e+01\n",
      "   7.00000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   6.82649326e+01   5.17335230e-04   7.12095425e+01\n",
      "   7.10000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   6.96052930e+01   6.08909516e-04   7.00325507e+01\n",
      "   7.20000000e+01] -1.0 False {}\n",
      "[  1.50000000e+01   7.09458191e+01   7.74499617e-04   6.88869543e+01\n",
      "   7.30000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   7.18400594e+01   1.07257244e-03   6.81397288e+01\n",
      "   7.40000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.22881559e+01   1.51263779e-03   6.77703569e+01\n",
      "   7.50000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   7.31833708e+01   2.04716503e-03   6.70421125e+01\n",
      "   7.60000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   7.40793727e+01   2.83427683e-03   6.63261384e+01\n",
      "   7.70000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   7.49765319e+01   3.99140917e-03   6.56220773e+01\n",
      "   7.80000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.54288057e+01   5.68997607e-03   6.52730137e+01\n",
      "   7.90000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.54365553e+01   7.74962676e-03   6.52697991e+01\n",
      "   8.00000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.58929553e+01   9.81608221e-03   6.49226613e+01\n",
      "   8.10000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.59052802e+01   1.23249455e-02   6.49187865e+01\n",
      "   8.20000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.59201272e+01   1.48469689e-02   6.49142830e+01\n",
      "   8.30000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.63840960e+01   1.73849358e-02   6.45692016e+01\n",
      "   8.40000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   7.72977381e+01   2.04744861e-02   6.38943519e+01\n",
      "   8.50000000e+01] -1.0 False {}\n",
      "[  1.00000000e+01   7.82159242e+01   2.50183072e-02   6.32369634e+01\n",
      "   8.60000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.86942083e+01   3.17002474e-02   6.29262894e+01\n",
      "   8.70000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.87340705e+01   3.98622655e-02   6.29557886e+01\n",
      "   8.80000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.87822319e+01   4.81613291e-02   6.29939396e+01\n",
      "   8.90000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.88388609e+01   5.66290006e-02   6.30416765e+01\n",
      "   9.00000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.89041601e+01   6.52992506e-02   6.31001725e+01\n",
      "   9.10000000e+01] -1.0 False {}\n",
      "[  5.00000000e+00   7.94249530e+01   7.42090346e-02   6.28499389e+01\n",
      "   9.20000000e+01] -1.0 False {}\n",
      "[  0.00000000e+00   7.95102309e+01   8.52779349e-02   6.29654919e+01\n",
      "   9.30000000e+01] -1.0 False {}\n",
      "[  0.          79.60697743   0.0967465   63.10518253  94.        ] -1.0 False {}\n",
      "[  0.          79.71566315   0.10868572  63.27301284  95.        ] -1.0 False {}\n",
      "[  0.          79.83683959   0.12117644  63.4739723   96.        ] -1.0 False {}\n",
      "[  0.          79.97115128   0.13431169  63.71429528  97.        ] -1.0 False {}\n",
      "[  0.          80.11935099   0.1481997   64.0018056   98.        ] -1.0 False {}\n",
      "[  0.          80.28231875   0.16296776  64.34638276  99.        ] -1.0 False {}\n",
      "[   0.           80.46108587    0.17876712   64.76059973  100.        ] -1.0 False {}\n",
      "[   5.           81.1034493     0.19577957   64.94952594  101.        ] -1.0 False {}\n",
      "[   0.           81.32140789    0.21795859   65.71625888  102.        ] -1.0 False {}\n",
      "[   5.           82.01021236    0.24222062   66.35982802  103.        ] -1.0 False {}\n",
      "[   0.           82.28462997    0.2744176    67.83649427  104.        ] -1.0 False {}\n",
      "[   0.           82.59507561    0.31044564   69.73349604  105.        ] -1.0 False {}\n",
      "[   0.           82.94642712    0.35135151   72.2042286   106.        ] -1.0 False {}\n",
      "[   5.           83.79157755    0.39856658   75.18245379  107.        ] -1.0 False {}\n",
      "[   0.           84.25673655    0.465159     80.62825611  108.        ] -1.0 False {}\n",
      "[   0.           84.80230745    0.5455709    88.40012987  109.        ] -1.0 False {}\n",
      "[   0.           85.44813239    0.64582494   99.92788229  110.        ] -1.0 False {}\n",
      "[   5.           86.67059036    0.77587412  117.64163386  111.        ] -1.0 False {}\n",
      "[   5.           88.1053245     0.98815028  154.19881292  112.        ] -1 True {}\n",
      "[  5.00000000e+00   3.74411051e+01   2.13854551e-11   1.25292057e+02\n",
      "   1.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+00   3.78822101e+01   4.84853418e-11   1.24370551e+02\n",
      "   2.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.78822101e+01   8.28035601e-11   1.24370551e+02\n",
      "   3.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.78822101e+01   1.17121778e-10   1.24370551e+02\n",
      "   4.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+00   3.83233152e+01   1.51439997e-10   1.23460420e+02\n",
      "   5.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.83233152e+01   1.94870165e-10   1.23460420e+02\n",
      "   6.00000000e+00] -1.0 False {}\n",
      "[  0.00000000e+00   3.83233152e+01   2.38300333e-10   1.23460420e+02\n",
      "   7.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+00   3.87644203e+01   2.81730501e-10   1.22561462e+02\n",
      "   8.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+00   3.92055254e+01   3.36655371e-10   1.21673479e+02\n",
      "   9.00000000e+00] -1.0 False {}\n",
      "[  1.00000000e+01   4.00877355e+01   4.06071204e-10   1.19929670e+02\n",
      "   1.00000000e+01] -1.0 False {}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "rewards = []\n",
    "for _ in range(500):\n",
    "    env.render()\n",
    "    state, reward, done, info = env.step(env.action_space.sample()) # take a random action\n",
    "    print(state, reward, done, info)\n",
    "    rewards.append(reward)\n",
    "    if done:\n",
    "        rewards = []\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n"
     ]
    }
   ],
   "source": [
    "print(rewards[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class QNetwork:\n",
    "    def __init__(self, learning_rate=0.01, state_size=5, \n",
    "                 action_size=3, hidden_size=10, \n",
    "                 name='QNetwork'):\n",
    "        # state inputs to the Q-network\n",
    "        with tf.variable_scope(name):\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, state_size], name='inputs')\n",
    "            \n",
    "            # One hot encode the actions to later choose the Q-value for the action\n",
    "            self.actions_ = tf.placeholder(tf.int32, [None], name='actions')\n",
    "            one_hot_actions = tf.one_hot(self.actions_, action_size)\n",
    "            \n",
    "            # Target Q values for training\n",
    "            self.targetQs_ = tf.placeholder(tf.float32, [None], name='target')\n",
    "            \n",
    "            # ReLU hidden layers\n",
    "            self.fc1 = tf.contrib.layers.fully_connected(self.inputs_, hidden_size)\n",
    "            self.fc2 = tf.contrib.layers.fully_connected(self.fc1, hidden_size)\n",
    "\n",
    "            # Linear output layer\n",
    "            self.output = tf.contrib.layers.fully_connected(self.fc2, action_size, \n",
    "                                                            activation_fn=None)\n",
    "            \n",
    "            ### Train with loss (targetQ - Q)^2\n",
    "            # output has length 2, for two actions. This next line chooses\n",
    "            # one value from output (per row) according to the one-hot encoded actions.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=1)\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_episodes = 500          # max number of episodes to learn from\n",
    "max_steps = 400                # max steps in an episode\n",
    "gamma = 0.99                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0002            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_size = 128               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 10000            # memory capacity\n",
    "batch_size = 40                # experience mini-batch size  (20, -80) (40 , -60 rew) (80, -55) (160, -55)\n",
    "pretrain_length = batch_size   # number experiences to pretrain the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = QNetwork(name='main', hidden_size=hidden_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initialize the simulation\n",
    "env.reset()\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for ii in range(pretrain_length):\n",
    "    # Uncomment the line below to watch the simulation\n",
    "    env.render()\n",
    "\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Total reward: -51.0 Training loss: 9.1574 Explore P: 0.9900 State: [   35.           100.             3.22194337  1118.74810558    92.        ]\n",
      "Episode: 2 Total reward: -47.0 Training loss: 1.1201 Explore P: 0.9808 State: [  35.           96.89157045    2.1616495   517.52415536   48.        ]\n",
      "Episode: 3 Total reward: -120.0 Training loss: 0.8597 Explore P: 0.9578 State: [   5.           87.48528659    0.80621146  105.62162474  121.        ]\n",
      "Episode: 4 Total reward: -25.0 Training loss: 0.6730 Explore P: 0.9530 State: [   40.           100.             6.68672356  4562.31269858    26.        ]\n",
      "Episode: 5 Total reward: -71.0 Training loss: 1.4585 Explore P: 0.9397 State: [  50.           95.29020018    1.30351719  209.86451887   72.        ]\n",
      "Episode: 6 Total reward: -52.0 Training loss: 0.5442 Explore P: 0.9301 State: [  25.           95.61913516    2.1564369   510.68892976   53.        ]\n",
      "Episode: 7 Total reward: -150.0 Training loss: 0.4439 Explore P: 0.9029 State: [  30.           93.21867579    1.18052473  184.41404441  151.        ]\n",
      "Episode: 8 Total reward: -121.0 Training loss: 0.3196 Explore P: 0.8816 State: [  40.           93.91241264    1.60248869  290.56421409  122.        ]\n",
      "Episode: 9 Total reward: -57.0 Training loss: 3.8634 Explore P: 0.8717 State: [  40.           96.42109163    1.73505413  359.20419653   58.        ]\n",
      "Episode: 10 Total reward: -47.0 Training loss: 0.4260 Explore P: 0.8636 State: [  30.           93.27093549    1.42588659  237.43693631   48.        ]\n",
      "Episode: 11 Total reward: -21.0 Training loss: 0.6484 Explore P: 0.8601 State: [  35.           94.90461287    0.81658187  158.20099268   22.        ]\n",
      "Episode: 12 Total reward: -18.0 Training loss: 0.2465 Explore P: 0.8570 State: [  40.           97.78401461    1.48628     289.699671     19.        ]\n",
      "Episode: 13 Total reward: -30.0 Training loss: 6.7803 Explore P: 0.8519 State: [  30.           95.74694949    1.15653347  208.5616992    31.        ]\n",
      "Episode: 14 Total reward: -28.0 Training loss: 3.6470 Explore P: 0.8472 State: [  45.           93.54122102    1.08192766  151.50706555   29.        ]\n",
      "Episode: 15 Total reward: -33.0 Training loss: 0.5393 Explore P: 0.8417 State: [  25.           94.00211062    1.02197669  180.93920812   34.        ]\n",
      "Episode: 16 Total reward: -29.0 Training loss: 0.4714 Explore P: 0.8369 State: [  35.           95.58542124    1.46099266  264.827305     30.        ]\n",
      "Episode: 17 Total reward: -53.0 Training loss: 3.7558 Explore P: 0.8282 State: [  30.           96.80514425    2.43494712  641.09196148   54.        ]\n",
      "Episode: 18 Total reward: -22.0 Training loss: 0.2376 Explore P: 0.8246 State: [  30.           94.89410655    1.2654411   223.72406333   23.        ]\n",
      "Episode: 19 Total reward: -23.0 Training loss: 0.9323 Explore P: 0.8209 State: [  50.           97.20472786    1.65851045  320.26044747   24.        ]\n",
      "Episode: 20 Total reward: -21.0 Training loss: 2.7317 Explore P: 0.8175 State: [  35.           93.6478887     0.89551126  138.07537376   22.        ]\n",
      "Episode: 21 Total reward: -50.0 Training loss: 1.4554 Explore P: 0.8094 State: [  20.           91.73897899    1.23931766  188.58114141   51.        ]\n",
      "Episode: 22 Total reward: -30.0 Training loss: 0.1947 Explore P: 0.8047 State: [  50.           97.11920291    2.204578    527.3095303    31.        ]\n",
      "Episode: 23 Total reward: -44.0 Training loss: 0.2335 Explore P: 0.7977 State: [  15.           90.3937581     0.97390367  156.03284562   45.        ]\n",
      "Episode: 24 Total reward: -24.0 Training loss: 0.4983 Explore P: 0.7939 State: [   35.           100.             4.41510371  2007.2191027     25.        ]\n",
      "Episode: 25 Total reward: -33.0 Training loss: 2.1196 Explore P: 0.7888 State: [  50.           93.57135373    0.86506218  116.09353232   34.        ]\n",
      "Episode: 26 Total reward: -54.0 Training loss: 0.2155 Explore P: 0.7804 State: [   5.           90.38194078    1.16301294  210.12189118   55.        ]\n",
      "Episode: 27 Total reward: -20.0 Training loss: 0.5669 Explore P: 0.7773 State: [  20.           95.49527417    1.98556879  462.3717605    21.        ]\n",
      "Episode: 28 Total reward: -53.0 Training loss: 2.5424 Explore P: 0.7692 State: [   5.           91.32752551    1.21652633  216.27699158   54.        ]\n",
      "Episode: 29 Total reward: -33.0 Training loss: 2.1096 Explore P: 0.7642 State: [  45.           94.5340878     1.43104142  240.85499233   34.        ]\n",
      "Episode: 30 Total reward: -21.0 Training loss: 1.8124 Explore P: 0.7611 State: [   45.           100.             7.33026582  5439.23027652    22.        ]\n",
      "Episode: 31 Total reward: -22.0 Training loss: 0.3473 Explore P: 0.7578 State: [  35.           95.18938171    0.87790257  150.23728097   23.        ]\n",
      "Episode: 32 Total reward: -42.0 Training loss: 0.3138 Explore P: 0.7515 State: [  25.           94.66960028    1.84146127  390.6465873    43.        ]\n",
      "Episode: 33 Total reward: -26.0 Training loss: 0.1281 Explore P: 0.7477 State: [   35.            99.48187089     3.46285723  1240.94251662    27.        ]\n",
      "Episode: 34 Total reward: -52.0 Training loss: 0.1508 Explore P: 0.7400 State: [  10.           89.42666213    0.84309626  114.33632054   53.        ]\n",
      "Episode: 35 Total reward: -16.0 Training loss: 4.5879 Explore P: 0.7377 State: [  45.           97.6679918     1.21891414  229.24263185   17.        ]\n",
      "Episode: 36 Total reward: -30.0 Training loss: 2.3285 Explore P: 0.7334 State: [  10.           91.07114155    0.97870211  174.86909195   31.        ]\n",
      "Episode: 37 Total reward: -32.0 Training loss: 0.4228 Explore P: 0.7287 State: [  15.           91.25757494    0.91468058  142.63911696   33.        ]\n",
      "Episode: 38 Total reward: -48.0 Training loss: 1.6441 Explore P: 0.7219 State: [  20.           91.57100205    1.07385703  174.02745888   49.        ]\n",
      "Episode: 39 Total reward: -32.0 Training loss: 0.3749 Explore P: 0.7173 State: [  40.           91.94754712    0.87024469  116.60408424   33.        ]\n",
      "Episode: 40 Total reward: -47.0 Training loss: 0.2579 Explore P: 0.7107 State: [   35.           100.             3.36652446  1216.06035724    48.        ]\n",
      "Episode: 41 Total reward: -21.0 Training loss: 0.1724 Explore P: 0.7078 State: [  50.           98.5564704     2.38572961  612.63751159   22.        ]\n",
      "Episode: 42 Total reward: -29.0 Training loss: 3.2758 Explore P: 0.7037 State: [  35.           93.08999038    1.21462938  184.12897918   30.        ]\n",
      "Episode: 43 Total reward: -47.0 Training loss: 0.6495 Explore P: 0.6973 State: [  50.           93.68515249    1.00890785  138.66037066   48.        ]\n",
      "Episode: 44 Total reward: -46.0 Training loss: 0.3507 Explore P: 0.6910 State: [  30.           93.92388015    1.58147869  294.03533134   47.        ]\n",
      "Episode: 45 Total reward: -53.0 Training loss: 0.3093 Explore P: 0.6838 State: [  60.           95.81937023    1.7923292   355.56444041   54.        ]\n",
      "Episode: 46 Total reward: -30.0 Training loss: 1.6050 Explore P: 0.6798 State: [  25.           93.71985173    1.10881025  195.7116771    31.        ]\n",
      "Episode: 47 Total reward: -42.0 Training loss: 2.1940 Explore P: 0.6741 State: [  35.           91.95296471    0.84082524  112.50293621   43.        ]\n",
      "Episode: 48 Total reward: -44.0 Training loss: 3.9436 Explore P: 0.6683 State: [  55.           95.50705483    1.53540216  274.14772154   45.        ]\n",
      "Episode: 49 Total reward: -37.0 Training loss: 0.3998 Explore P: 0.6635 State: [  25.           94.23910292    1.60092165  305.68236845   38.        ]\n",
      "Episode: 50 Total reward: -31.0 Training loss: 1.6872 Explore P: 0.6594 State: [  25.           91.40760158    0.85184318  127.60797736   32.        ]\n",
      "Episode: 51 Total reward: -18.0 Training loss: 2.1839 Explore P: 0.6571 State: [  20.           95.32114209    1.57246677  318.63238384   19.        ]\n",
      "Episode: 52 Total reward: -38.0 Training loss: 0.3729 Explore P: 0.6522 State: [  45.           94.39987375    1.24117411  194.33316391   39.        ]\n",
      "Episode: 53 Total reward: -33.0 Training loss: 4.5112 Explore P: 0.6480 State: [  30.           91.60381424    0.80970913  116.49400896   34.        ]\n",
      "Episode: 54 Total reward: -28.0 Training loss: 0.2936 Explore P: 0.6444 State: [  70.           96.72796224    1.67324595  313.27383216   29.        ]\n",
      "Episode: 55 Total reward: -19.0 Training loss: 0.3388 Explore P: 0.6420 State: [  40.           95.12625097    1.03167584  163.51716483   20.        ]\n",
      "Episode: 56 Total reward: -50.0 Training loss: 2.3531 Explore P: 0.6357 State: [  30.           94.57847951    1.7729826   357.03938315   51.        ]\n",
      "Episode: 57 Total reward: -33.0 Training loss: 0.3738 Explore P: 0.6316 State: [  25.           97.25647517    2.46852291  666.44882507   34.        ]\n",
      "Episode: 58 Total reward: -37.0 Training loss: 0.3361 Explore P: 0.6270 State: [  55.           98.32337519    2.64501142  740.19295431   38.        ]\n",
      "Episode: 59 Total reward: -36.0 Training loss: 1.6090 Explore P: 0.6226 State: [  45.           96.27281269    2.12805046  492.79294417   37.        ]\n",
      "Episode: 60 Total reward: -35.0 Training loss: 0.2796 Explore P: 0.6183 State: [  35.           92.3113735     0.87217021  121.46328829   36.        ]\n",
      "Episode: 61 Total reward: -20.0 Training loss: 1.7690 Explore P: 0.6159 State: [  25.           92.85878602    0.83037924  135.10658027   21.        ]\n",
      "Episode: 62 Total reward: -38.0 Training loss: 0.2156 Explore P: 0.6113 State: [  75.           95.52439156    1.21830001  185.79672295   39.        ]\n",
      "Episode: 63 Total reward: -47.0 Training loss: 0.4656 Explore P: 0.6057 State: [  35.           97.63304543    2.71601541  785.36525718   48.        ]\n",
      "Episode: 64 Total reward: -31.0 Training loss: 3.4930 Explore P: 0.6020 State: [  30.           95.68114466    1.96337183  440.61095939   32.        ]\n",
      "Episode: 65 Total reward: -39.0 Training loss: 2.5968 Explore P: 0.5974 State: [  20.           92.4314789     1.18140832  191.51602386   40.        ]\n",
      "Episode: 66 Total reward: -23.0 Training loss: 0.3428 Explore P: 0.5947 State: [  45.           99.20033052    3.00174729  946.9448306    24.        ]\n",
      "Episode: 67 Total reward: -32.0 Training loss: 3.0859 Explore P: 0.5910 State: [  45.           98.20892841    1.99773247  449.22425635   33.        ]\n",
      "Episode: 68 Total reward: -32.0 Training loss: 0.4498 Explore P: 0.5873 State: [  40.           98.05387862    2.94009094  904.83575777   33.        ]\n",
      "Episode: 69 Total reward: -22.0 Training loss: 0.2850 Explore P: 0.5847 State: [  35.           97.94971161    2.11105374  509.38362529   23.        ]\n",
      "Episode: 70 Total reward: -24.0 Training loss: 2.9403 Explore P: 0.5820 State: [  40.           99.52100043    3.05596838  991.22225538   25.        ]\n",
      "Episode: 71 Total reward: -33.0 Training loss: 3.4938 Explore P: 0.5782 State: [  25.           96.8121148     2.44051751  653.00231438   34.        ]\n",
      "Episode: 72 Total reward: -39.0 Training loss: 0.7204 Explore P: 0.5738 State: [  25.           94.45354302    1.67835511  327.09495707   40.        ]\n",
      "Episode: 73 Total reward: -43.0 Training loss: 1.5964 Explore P: 0.5690 State: [  30.           93.05887359    1.27393871  200.56425989   44.        ]\n",
      "Episode: 74 Total reward: -33.0 Training loss: 3.2975 Explore P: 0.5653 State: [   55.            99.92769955     3.26207473  1096.91958869    34.        ]\n",
      "Episode: 75 Total reward: -40.0 Training loss: 3.9489 Explore P: 0.5609 State: [  45.           94.16352033    1.35071315  222.70428674   41.        ]\n",
      "Episode: 76 Total reward: -35.0 Training loss: 2.3354 Explore P: 0.5570 State: [  35.           93.48192137    1.17812006  184.00908225   36.        ]\n",
      "Episode: 77 Total reward: -40.0 Training loss: 2.0245 Explore P: 0.5527 State: [  45.           93.89177399    1.23139796  188.48275897   41.        ]\n",
      "Episode: 78 Total reward: -17.0 Training loss: 6.5421 Explore P: 0.5508 State: [  30.           95.4369506     1.25635089  228.50519238   18.        ]\n",
      "Episode: 79 Total reward: -26.0 Training loss: 0.3582 Explore P: 0.5480 State: [  35.           93.66469234    0.81620392  122.20821743   27.        ]\n",
      "Episode: 80 Total reward: -30.0 Training loss: 2.3464 Explore P: 0.5448 State: [   60.           100.             3.21399927  1068.39197735    31.        ]\n",
      "Episode: 81 Total reward: -39.0 Training loss: 0.5150 Explore P: 0.5407 State: [  55.           93.54083551    0.92340651  125.42817167   40.        ]\n",
      "Episode: 82 Total reward: -33.0 Training loss: 5.8383 Explore P: 0.5372 State: [  25.           94.18832992    1.57822034  304.48951197   34.        ]\n",
      "Episode: 83 Total reward: -41.0 Training loss: 0.2656 Explore P: 0.5329 State: [  55.           96.81761314    2.25940741  544.64443073   42.        ]\n",
      "Episode: 84 Total reward: -36.0 Training loss: 1.7841 Explore P: 0.5291 State: [  65.           99.94585663    3.08408009  987.05238645   37.        ]\n",
      "Episode: 85 Total reward: -31.0 Training loss: 0.2769 Explore P: 0.5259 State: [  40.           97.00817619    2.48191307  655.79812391   32.        ]\n",
      "Episode: 86 Total reward: -38.0 Training loss: 2.3617 Explore P: 0.5220 State: [  30.           92.94014107    1.17294943  181.05121998   39.        ]\n",
      "Episode: 87 Total reward: -31.0 Training loss: 3.1003 Explore P: 0.5188 State: [  55.           94.87921637    1.05159489  148.70782196   32.        ]\n",
      "Episode: 88 Total reward: -31.0 Training loss: 0.6891 Explore P: 0.5157 State: [  20.           91.38189148    0.8310327   121.6642159    32.        ]\n",
      "Episode: 89 Total reward: -16.0 Training loss: 1.7269 Explore P: 0.5141 State: [  4.00000000e+01   1.00000000e+02   1.14047755e+01   1.30850310e+04\n",
      "   1.70000000e+01]\n",
      "Episode: 90 Total reward: -46.0 Training loss: 2.0035 Explore P: 0.5094 State: [   65.           100.             3.62881737  1348.69254038    47.        ]\n",
      "Episode: 91 Total reward: -31.0 Training loss: 0.2904 Explore P: 0.5064 State: [  35.           92.6691664     1.10369552  157.10870294   32.        ]\n",
      "Episode: 92 Total reward: -37.0 Training loss: 0.4333 Explore P: 0.5027 State: [  35.           94.53304152    1.4225027   248.85124622   38.        ]\n",
      "Episode: 93 Total reward: -27.0 Training loss: 2.1814 Explore P: 0.5000 State: [  20.           94.3925642     1.70376602  349.95078963   28.        ]\n",
      "Episode: 94 Total reward: -31.0 Training loss: 0.2127 Explore P: 0.4970 State: [  25.           93.54953749    1.39862454  245.00778114   32.        ]\n",
      "Episode: 95 Total reward: -37.0 Training loss: 0.2922 Explore P: 0.4934 State: [  50.           96.28893113    2.12307483  487.22294577   38.        ]\n",
      "Episode: 96 Total reward: -45.0 Training loss: 1.9425 Explore P: 0.4891 State: [  55.           96.83317708    2.32416634  575.43541395   46.        ]\n",
      "Episode: 97 Total reward: -43.0 Training loss: 4.9769 Explore P: 0.4850 State: [  45.           95.5139224     2.02410054  444.89540783   44.        ]\n",
      "Episode: 98 Total reward: -21.0 Training loss: 3.5602 Explore P: 0.4830 State: [  20.           98.3786592     2.95619318  947.28877067   22.        ]\n",
      "Episode: 99 Total reward: -33.0 Training loss: 2.5692 Explore P: 0.4799 State: [  25.           92.04257785    1.06666299  166.55881739   34.        ]\n",
      "Episode: 100 Total reward: -30.0 Training loss: 0.3190 Explore P: 0.4771 State: [  30.           92.50079324    0.9075316   134.51644976   31.        ]\n",
      "Episode: 101 Total reward: -27.0 Training loss: 0.3789 Explore P: 0.4746 State: [  15.           92.77765152    1.09521024  219.41210378   28.        ]\n",
      "Episode: 102 Total reward: -28.0 Training loss: 10.7662 Explore P: 0.4720 State: [   45.           100.             3.65275661  1378.86366175    29.        ]\n",
      "Episode: 103 Total reward: -42.0 Training loss: 7.3099 Explore P: 0.4681 State: [  25.           93.86060718    1.43985909  261.98474246   43.        ]\n",
      "Episode: 104 Total reward: -46.0 Training loss: 0.4458 Explore P: 0.4639 State: [  60.           94.33222104    1.1035024   155.70763396   47.        ]\n",
      "Episode: 105 Total reward: -34.0 Training loss: 2.1559 Explore P: 0.4608 State: [   50.           100.             3.70978718  1422.46783334    35.        ]\n",
      "Episode: 106 Total reward: -18.0 Training loss: 0.3401 Explore P: 0.4592 State: [   30.           100.             6.20112145  3925.14563594    19.        ]\n",
      "Episode: 107 Total reward: -36.0 Training loss: 0.6410 Explore P: 0.4560 State: [   50.            99.39927416     3.21160843  1066.73099127    37.        ]\n",
      "Episode: 108 Total reward: -30.0 Training loss: 0.4546 Explore P: 0.4533 State: [  20.           91.63349327    0.83158191  128.81369555   31.        ]\n",
      "Episode: 109 Total reward: -33.0 Training loss: 0.3665 Explore P: 0.4504 State: [  20.           91.7986625     1.16669809  198.17128616   34.        ]\n",
      "Episode: 110 Total reward: -31.0 Training loss: 5.3252 Explore P: 0.4477 State: [  30.           91.22074552    0.82804002  110.55293749   32.        ]\n",
      "Episode: 111 Total reward: -27.0 Training loss: 2.7630 Explore P: 0.4453 State: [   5.           89.04014066    0.90503007  167.16470484   28.        ]\n",
      "Episode: 112 Total reward: -38.0 Training loss: 2.0880 Explore P: 0.4420 State: [  75.           95.37073736    1.24649104  188.26148983   39.        ]\n",
      "Episode: 113 Total reward: -40.0 Training loss: 5.2466 Explore P: 0.4386 State: [  45.           92.47697471    0.88494834  114.19189082   41.        ]\n",
      "Episode: 114 Total reward: -19.0 Training loss: 2.4658 Explore P: 0.4370 State: [  10.           91.37274477    0.80110872  163.37939203   20.        ]\n",
      "Episode: 115 Total reward: -24.0 Training loss: 0.6697 Explore P: 0.4349 State: [  10.           93.50150385    1.60683007  334.8571821    25.        ]\n",
      "Episode: 116 Total reward: -41.0 Training loss: 0.4688 Explore P: 0.4315 State: [  55.           94.78470479    0.90097052  126.83291633   42.        ]\n",
      "Episode: 117 Total reward: -33.0 Training loss: 4.1517 Explore P: 0.4287 State: [  15.           90.49496494    0.84976583  127.13356052   34.        ]\n",
      "Episode: 118 Total reward: -36.0 Training loss: 2.2007 Explore P: 0.4257 State: [  55.           94.321469      1.16998631  173.32123782   37.        ]\n",
      "Episode: 119 Total reward: -32.0 Training loss: 4.8064 Explore P: 0.4230 State: [  70.          100.            3.01904298  945.30266632   33.        ]\n",
      "Episode: 120 Total reward: -39.0 Training loss: 1.9853 Explore P: 0.4198 State: [  55.           94.30669267    0.95243997  128.18948753   40.        ]\n",
      "Episode: 121 Total reward: -40.0 Training loss: 3.9070 Explore P: 0.4165 State: [   65.            99.44732894     3.25953506  1096.45342985    41.        ]\n",
      "Episode: 122 Total reward: -23.0 Training loss: 0.4751 Explore P: 0.4147 State: [  10.           94.82219845    1.98216753  480.15880065   24.        ]\n",
      "Episode: 123 Total reward: -42.0 Training loss: 0.4479 Explore P: 0.4113 State: [  65.           96.96621183    1.5402006   278.9085711    43.        ]\n",
      "Episode: 124 Total reward: -38.0 Training loss: 6.4802 Explore P: 0.4083 State: [  45.           95.93608188    1.38403407  247.31410715   39.        ]\n",
      "Episode: 125 Total reward: -33.0 Training loss: 0.3034 Explore P: 0.4056 State: [  55.           96.07258782    1.43151926  245.25989477   34.        ]\n",
      "Episode: 126 Total reward: -31.0 Training loss: 5.2994 Explore P: 0.4032 State: [  15.           93.10170946    1.59861234  314.86668101   32.        ]\n",
      "Episode: 127 Total reward: -30.0 Training loss: 3.2344 Explore P: 0.4008 State: [  50.           95.29255809    0.98266412  155.85080902   31.        ]\n",
      "Episode: 128 Total reward: -22.0 Training loss: 5.9224 Explore P: 0.3991 State: [  35.           96.29630183    1.41204987  266.98404288   23.        ]\n",
      "Episode: 129 Total reward: -32.0 Training loss: 2.0069 Explore P: 0.3966 State: [  15.           91.21882474    0.88477574  160.3021065    33.        ]\n",
      "Episode: 130 Total reward: -41.0 Training loss: 3.7955 Explore P: 0.3935 State: [  65.           95.53841634    1.20892977  181.75907973   42.        ]\n",
      "Episode: 131 Total reward: -16.0 Training loss: 3.2772 Explore P: 0.3923 State: [  40.           99.6852437     2.49264784  692.93629376   17.        ]\n",
      "Episode: 132 Total reward: -34.0 Training loss: 0.2794 Explore P: 0.3897 State: [   45.            98.9511357      3.1527455   1038.76268117    35.        ]\n",
      "Episode: 133 Total reward: -37.0 Training loss: 2.0980 Explore P: 0.3869 State: [  40.           96.20327027    1.33388256  237.47523574   38.        ]\n",
      "Episode: 134 Total reward: -40.0 Training loss: 2.7230 Explore P: 0.3839 State: [  25.           93.60394853    1.35679524  237.08569811   41.        ]\n",
      "Episode: 135 Total reward: -35.0 Training loss: 9.9713 Explore P: 0.3813 State: [  70.           98.71979623    2.47893737  646.236596     36.        ]\n",
      "Episode: 136 Total reward: -36.0 Training loss: 1.6330 Explore P: 0.3786 State: [  50.           97.32155042    2.39467982  612.52807208   37.        ]\n",
      "Episode: 137 Total reward: -32.0 Training loss: 0.3284 Explore P: 0.3762 State: [   35.           100.             3.80481374  1518.28331928    33.        ]\n",
      "Episode: 138 Total reward: -23.0 Training loss: 1.4723 Explore P: 0.3746 State: [  35.           98.54389374    2.43104635  662.81434043   24.        ]\n",
      "Episode: 139 Total reward: -29.0 Training loss: 1.7853 Explore P: 0.3725 State: [  50.           94.21857012    0.81344003  122.06877827   30.        ]\n",
      "Episode: 140 Total reward: -37.0 Training loss: 0.3000 Explore P: 0.3698 State: [  50.           95.87074315    1.61576409  295.3800358    38.        ]\n",
      "Episode: 141 Total reward: -31.0 Training loss: 7.8982 Explore P: 0.3676 State: [  35.           92.92184431    0.88707006  137.78845649   32.        ]\n",
      "Episode: 142 Total reward: -36.0 Training loss: 0.3271 Explore P: 0.3650 State: [  45.           93.33257551    0.87105191  119.40243817   37.        ]\n",
      "Episode: 143 Total reward: -39.0 Training loss: 9.8730 Explore P: 0.3622 State: [  55.           95.69979481    1.02326327  148.40757563   40.        ]\n",
      "Episode: 144 Total reward: -16.0 Training loss: 3.1439 Explore P: 0.3611 State: [  30.           96.96338175    1.78898058  401.45131103   17.        ]\n",
      "Episode: 145 Total reward: -25.0 Training loss: 1.7514 Explore P: 0.3594 State: [  35.           93.60234753    0.87765239  130.59242004   26.        ]\n",
      "Episode: 146 Total reward: -26.0 Training loss: 0.2394 Explore P: 0.3575 State: [  35.           96.49128658    2.42318402  627.92053641   27.        ]\n",
      "Episode: 147 Total reward: -47.0 Training loss: 3.7624 Explore P: 0.3543 State: [  45.           95.52166003    2.026062    443.77625681   48.        ]\n",
      "Episode: 148 Total reward: -40.0 Training loss: 2.0939 Explore P: 0.3516 State: [  30.           92.93206737    1.2141715   186.90379374   41.        ]\n",
      "Episode: 149 Total reward: -40.0 Training loss: 4.1689 Explore P: 0.3488 State: [  65.           98.61970415    2.23801355  536.24420798   41.        ]\n",
      "Episode: 150 Total reward: -43.0 Training loss: 4.8272 Explore P: 0.3459 State: [  50.           97.21783686    2.43600798  630.16710768   44.        ]\n",
      "Episode: 151 Total reward: -16.0 Training loss: 3.4916 Explore P: 0.3449 State: [  10.           95.97328934    2.40098483  669.34457325   17.        ]\n",
      "Episode: 152 Total reward: -42.0 Training loss: 1.0806 Explore P: 0.3421 State: [  40.           96.2163265     2.14373824  493.79448034   43.        ]\n",
      "Episode: 153 Total reward: -31.0 Training loss: 2.2629 Explore P: 0.3400 State: [  25.           97.14208052    2.46276297  679.05524218   32.        ]\n",
      "Episode: 154 Total reward: -35.0 Training loss: 2.6761 Explore P: 0.3377 State: [   0.          87.1097867    0.921451   177.3951032   36.       ]\n",
      "Episode: 155 Total reward: -37.0 Training loss: 9.4026 Explore P: 0.3353 State: [  50.           96.68797855    1.39756289  249.9488924    38.        ]\n",
      "Episode: 156 Total reward: -28.0 Training loss: 6.8090 Explore P: 0.3335 State: [  25.           92.65842134    0.8059488   140.75293669   29.        ]\n",
      "Episode: 157 Total reward: -25.0 Training loss: 1.5647 Explore P: 0.3319 State: [   40.           100.             6.0751294   3776.23767137    26.        ]\n",
      "Episode: 158 Total reward: -40.0 Training loss: 3.8787 Explore P: 0.3293 State: [  70.           96.04554336    1.49561227  260.62693701   41.        ]\n",
      "Episode: 159 Total reward: -35.0 Training loss: 0.5315 Explore P: 0.3271 State: [  60.           94.62655394    0.85446705  115.25894504   36.        ]\n",
      "Episode: 160 Total reward: -29.0 Training loss: 0.4493 Explore P: 0.3252 State: [  55.           97.34268066    1.84127453  388.02250429   30.        ]\n",
      "Episode: 161 Total reward: -37.0 Training loss: 0.2489 Explore P: 0.3229 State: [  60.           96.55439233    1.75688672  349.86663219   38.        ]\n",
      "Episode: 162 Total reward: -37.0 Training loss: 0.3590 Explore P: 0.3206 State: [   65.           100.             5.03646132  2574.96278519    38.        ]\n",
      "Episode: 163 Total reward: -29.0 Training loss: 4.6159 Explore P: 0.3188 State: [  55.           98.07531535    2.08633368  476.56525411   30.        ]\n",
      "Episode: 164 Total reward: -27.0 Training loss: 1.2228 Explore P: 0.3171 State: [  20.           94.18196954    1.53633236  305.32390339   28.        ]\n",
      "Episode: 165 Total reward: -21.0 Training loss: 2.7029 Explore P: 0.3159 State: [  30.           95.8553009     0.96441534  187.89978927   22.        ]\n",
      "Episode: 166 Total reward: -38.0 Training loss: 5.5178 Explore P: 0.3135 State: [  35.           95.16000964    1.66245434  329.35911446   39.        ]\n",
      "Episode: 167 Total reward: -32.0 Training loss: 3.9187 Explore P: 0.3116 State: [  50.           97.91146442    2.29877294  574.97441666   33.        ]\n",
      "Episode: 168 Total reward: -36.0 Training loss: 0.4182 Explore P: 0.3094 State: [  45.           96.75973883    2.22184214  534.67295413   37.        ]\n",
      "Episode: 169 Total reward: -29.0 Training loss: 10.1143 Explore P: 0.3077 State: [  50.           97.88052004    1.78595425  370.3681029    30.        ]\n",
      "Episode: 170 Total reward: -27.0 Training loss: 3.2427 Explore P: 0.3061 State: [  30.           99.86957403    2.71447522  815.72112377   28.        ]\n",
      "Episode: 171 Total reward: -24.0 Training loss: 2.4443 Explore P: 0.3047 State: [  30.           92.72668412    0.83001776  131.59931402   25.        ]\n",
      "Episode: 172 Total reward: -28.0 Training loss: 3.2900 Explore P: 0.3030 State: [  25.           94.00854634    1.53480306  287.70384176   29.        ]\n",
      "Episode: 173 Total reward: -41.0 Training loss: 0.3470 Explore P: 0.3006 State: [   50.            99.41453694     3.12361748  1011.62566876    42.        ]\n",
      "Episode: 174 Total reward: -29.0 Training loss: 6.6445 Explore P: 0.2990 State: [  60.           95.7388707     1.48473891  258.08702325   30.        ]\n",
      "Episode: 175 Total reward: -34.0 Training loss: 1.9595 Explore P: 0.2970 State: [  55.           98.09068504    1.97664034  442.7070012    35.        ]\n",
      "Episode: 176 Total reward: -35.0 Training loss: 4.9258 Explore P: 0.2950 State: [  35.           96.09810007    1.71383718  348.20808799   36.        ]\n",
      "Episode: 177 Total reward: -19.0 Training loss: 0.5841 Explore P: 0.2939 State: [  50.           95.63426121    1.07519156  166.85255938   20.        ]\n",
      "Episode: 178 Total reward: -35.0 Training loss: 0.2675 Explore P: 0.2919 State: [  50.           94.62071191    1.17215285  174.16227949   36.        ]\n",
      "Episode: 179 Total reward: -37.0 Training loss: 3.9578 Explore P: 0.2899 State: [  75.           98.48187025    2.04931313  462.1948408    38.        ]\n",
      "Episode: 180 Total reward: -36.0 Training loss: 5.3922 Explore P: 0.2879 State: [  25.           93.43074037    1.34160557  248.87896334   37.        ]\n",
      "Episode: 181 Total reward: -34.0 Training loss: 2.2836 Explore P: 0.2860 State: [  65.           97.32703929    2.02165373  442.85604799   35.        ]\n",
      "Episode: 182 Total reward: -37.0 Training loss: 6.6640 Explore P: 0.2839 State: [  60.           96.0043657     1.32793938  214.49045504   38.        ]\n",
      "Episode: 183 Total reward: -39.0 Training loss: 0.2687 Explore P: 0.2818 State: [  35.           93.1978029     0.82956342  128.27288646   40.        ]\n",
      "Episode: 184 Total reward: -32.0 Training loss: 3.0654 Explore P: 0.2801 State: [  60.           98.46098867    2.76953954  799.2097842    33.        ]\n",
      "Episode: 185 Total reward: -18.0 Training loss: 0.2692 Explore P: 0.2791 State: [  45.           99.30698557    2.77694066  823.01821185   19.        ]\n",
      "Episode: 186 Total reward: -24.0 Training loss: 3.0572 Explore P: 0.2778 State: [  20.           92.28928949    0.90942589  149.40588349   25.        ]\n",
      "Episode: 187 Total reward: -24.0 Training loss: 7.2078 Explore P: 0.2765 State: [  25.           96.27456992    2.28231     582.18959625   25.        ]\n",
      "Episode: 188 Total reward: -28.0 Training loss: 1.9934 Explore P: 0.2750 State: [  65.           95.56147567    1.09564624  155.53025046   29.        ]\n",
      "Episode: 189 Total reward: -30.0 Training loss: 1.1450 Explore P: 0.2735 State: [  50.           97.22976157    2.14026654  494.24951428   31.        ]\n",
      "Episode: 190 Total reward: -27.0 Training loss: 2.3171 Explore P: 0.2720 State: [  25.           97.41313117    2.51907165  702.11539216   28.        ]\n",
      "Episode: 191 Total reward: -39.0 Training loss: 0.4017 Explore P: 0.2700 State: [  60.          100.            2.56297088  699.02382267   40.        ]\n",
      "Episode: 192 Total reward: -24.0 Training loss: 4.4865 Explore P: 0.2688 State: [   50.           100.             4.43738197  2047.93853826    25.        ]\n",
      "Episode: 193 Total reward: -27.0 Training loss: 0.5289 Explore P: 0.2674 State: [  20.           93.53851021    0.99689318  176.3157452    28.        ]\n",
      "Episode: 194 Total reward: -34.0 Training loss: 1.5397 Explore P: 0.2656 State: [   45.            99.47921261     3.34714283  1158.80640786    35.        ]\n",
      "Episode: 195 Total reward: -33.0 Training loss: 0.2604 Explore P: 0.2639 State: [  60.           97.75706496    1.88837734  402.19026302   34.        ]\n",
      "Episode: 196 Total reward: -29.0 Training loss: 3.6273 Explore P: 0.2625 State: [  50.           97.1950424     2.09025586  473.29629541   30.        ]\n",
      "Episode: 197 Total reward: -30.0 Training loss: 4.8783 Explore P: 0.2610 State: [  20.           96.46206807    1.94808399  466.34360091   31.        ]\n",
      "Episode: 198 Total reward: -33.0 Training loss: 6.4947 Explore P: 0.2593 State: [  50.           95.79993296    1.19534353  193.69017501   34.        ]\n",
      "Episode: 199 Total reward: -25.0 Training loss: 6.9079 Explore P: 0.2581 State: [  25.           93.39999762    1.32902345  219.90072587   26.        ]\n",
      "Episode: 200 Total reward: -39.0 Training loss: 0.4742 Explore P: 0.2561 State: [  40.           96.82815433    2.30257872  578.1402519    40.        ]\n",
      "Episode: 201 Total reward: -29.0 Training loss: 5.3502 Explore P: 0.2547 State: [  45.           95.41938424    1.45873545  254.29440704   30.        ]\n",
      "Episode: 202 Total reward: -22.0 Training loss: 1.8108 Explore P: 0.2536 State: [  35.           95.15112744    1.3649365   233.31247468   23.        ]\n",
      "Episode: 203 Total reward: -41.0 Training loss: 0.3816 Explore P: 0.2517 State: [  70.           94.84550735    0.84973182  105.39279818   42.        ]\n",
      "Episode: 204 Total reward: -34.0 Training loss: 1.1158 Explore P: 0.2500 State: [  60.           98.37211211    2.29626921  563.89156313   35.        ]\n",
      "Episode: 205 Total reward: -20.0 Training loss: 0.4215 Explore P: 0.2491 State: [  60.           97.13389294    1.61662553  305.28051328   21.        ]\n",
      "Episode: 206 Total reward: -28.0 Training loss: 7.4144 Explore P: 0.2477 State: [   40.           100.             8.48296507  7285.69507287    29.        ]\n",
      "Episode: 207 Total reward: -29.0 Training loss: 0.2799 Explore P: 0.2463 State: [  55.           97.26515501    1.98915998  431.11501324   30.        ]\n",
      "Episode: 208 Total reward: -31.0 Training loss: 3.4142 Explore P: 0.2449 State: [  45.           95.9429234     0.88609264  152.69724402   32.        ]\n",
      "Episode: 209 Total reward: -25.0 Training loss: 0.2913 Explore P: 0.2437 State: [  55.           99.41849148    2.70910786  775.8444642    26.        ]\n",
      "Episode: 210 Total reward: -28.0 Training loss: 0.5760 Explore P: 0.2424 State: [  10.           93.72065519    1.71859229  377.16693908   29.        ]\n",
      "Episode: 211 Total reward: -29.0 Training loss: 3.5309 Explore P: 0.2411 State: [  75.           95.34941974    0.83482063  108.92285534   30.        ]\n",
      "Episode: 212 Total reward: -20.0 Training loss: 4.2752 Explore P: 0.2401 State: [  25.           96.60705075    2.19108693  550.41819056   21.        ]\n",
      "Episode: 213 Total reward: -24.0 Training loss: 0.1893 Explore P: 0.2390 State: [  25.           92.82077841    0.93865313  149.43976227   25.        ]\n",
      "Episode: 214 Total reward: -33.0 Training loss: 3.4755 Explore P: 0.2375 State: [   80.           100.             4.0372923   1662.50702996    34.        ]\n",
      "Episode: 215 Total reward: -32.0 Training loss: 0.3507 Explore P: 0.2361 State: [   50.           100.             4.21887904  1817.51330135    33.        ]\n",
      "Episode: 216 Total reward: -31.0 Training loss: 1.9162 Explore P: 0.2347 State: [   35.            99.11683659     3.14429273  1040.90233528    32.        ]\n",
      "Episode: 217 Total reward: -28.0 Training loss: 2.8999 Explore P: 0.2334 State: [  35.           94.8966107     0.81485192  156.72432001   29.        ]\n",
      "Episode: 218 Total reward: -30.0 Training loss: 2.2141 Explore P: 0.2321 State: [  50.           98.50088034    2.37422493  610.93266466   31.        ]\n",
      "Episode: 219 Total reward: -29.0 Training loss: 3.9398 Explore P: 0.2308 State: [  20.           92.80009483    0.92538559  177.28363737   30.        ]\n",
      "Episode: 220 Total reward: -28.0 Training loss: 7.1281 Explore P: 0.2296 State: [  30.           95.54207522    2.12824021  493.01258844   29.        ]\n",
      "Episode: 221 Total reward: -17.0 Training loss: 2.6690 Explore P: 0.2288 State: [  25.           97.92707094    2.72172279  806.66282511   18.        ]\n",
      "Episode: 222 Total reward: -20.0 Training loss: 0.5998 Explore P: 0.2280 State: [  30.           96.83067528    1.98397167  455.20923991   21.        ]\n",
      "Episode: 223 Total reward: -21.0 Training loss: 1.1612 Explore P: 0.2270 State: [   40.           100.             3.23130082  1107.41086361    22.        ]\n",
      "Episode: 224 Total reward: -33.0 Training loss: 3.4775 Explore P: 0.2256 State: [  50.           96.95778473    1.35420549  247.43358996   34.        ]\n",
      "Episode: 225 Total reward: -39.0 Training loss: 4.5422 Explore P: 0.2239 State: [  50.           93.71638071    0.93799071  131.5263408    40.        ]\n",
      "Episode: 226 Total reward: -34.0 Training loss: 1.9466 Explore P: 0.2225 State: [  60.           94.91405666    0.89426254  119.29063586   35.        ]\n",
      "Episode: 227 Total reward: -37.0 Training loss: 2.4734 Explore P: 0.2209 State: [  60.           97.52994458    2.0531476   459.46910602   38.        ]\n",
      "Episode: 228 Total reward: -35.0 Training loss: 0.9594 Explore P: 0.2195 State: [  35.           97.17191641    0.9539257   183.49433189   36.        ]\n",
      "Episode: 229 Total reward: -35.0 Training loss: 0.2345 Explore P: 0.2180 State: [  55.           98.02669163    2.69656907  759.43771457   36.        ]\n",
      "Episode: 230 Total reward: -35.0 Training loss: 0.9542 Explore P: 0.2165 State: [  75.           96.65313783    1.51067623  261.85774027   36.        ]\n",
      "Episode: 231 Total reward: -23.0 Training loss: 0.8609 Explore P: 0.2156 State: [  60.           95.71236776    0.93301433  130.44896707   24.        ]\n",
      "Episode: 232 Total reward: -20.0 Training loss: 1.5008 Explore P: 0.2148 State: [  15.           92.2143447     0.85335646  156.60617269   21.        ]\n",
      "Episode: 233 Total reward: -28.0 Training loss: 3.5210 Explore P: 0.2136 State: [  35.           94.79794584    1.39155183  247.60117516   29.        ]\n",
      "Episode: 234 Total reward: -34.0 Training loss: 1.4110 Explore P: 0.2123 State: [  60.           94.64183528    1.16946029  176.59694681   35.        ]\n",
      "Episode: 235 Total reward: -28.0 Training loss: 8.6319 Explore P: 0.2111 State: [  10.           94.69403396    2.01347207  480.50450025   29.        ]\n",
      "Episode: 236 Total reward: -18.0 Training loss: 5.5158 Explore P: 0.2104 State: [  35.           98.00342927    2.58227001  727.92941401   19.        ]\n",
      "Episode: 237 Total reward: -34.0 Training loss: 4.7579 Explore P: 0.2090 State: [  35.           94.37562987    1.59930014  300.90717237   35.        ]\n",
      "Episode: 238 Total reward: -32.0 Training loss: 0.3507 Explore P: 0.2078 State: [  35.           92.274972      0.83204825  115.55113871   33.        ]\n",
      "Episode: 239 Total reward: -35.0 Training loss: 3.2369 Explore P: 0.2064 State: [  80.           96.28391259    1.23813015  189.70187294   36.        ]\n",
      "Episode: 240 Total reward: -24.0 Training loss: 3.1250 Explore P: 0.2055 State: [  15.           93.34158582    1.45947182  275.42910899   25.        ]\n",
      "Episode: 241 Total reward: -34.0 Training loss: 1.1450 Explore P: 0.2041 State: [   35.            99.31909595     3.36451188  1178.47764186    35.        ]\n",
      "Episode: 242 Total reward: -23.0 Training loss: 1.5692 Explore P: 0.2032 State: [  20.           96.94494293    2.5193136   694.03969728   24.        ]\n",
      "Episode: 243 Total reward: -39.0 Training loss: 2.1745 Explore P: 0.2017 State: [  50.           97.82728061    1.39536035  251.89819984   40.        ]\n",
      "Episode: 244 Total reward: -16.0 Training loss: 2.9368 Explore P: 0.2011 State: [  25.           96.07104833    1.66550751  357.09434201   17.        ]\n",
      "Episode: 245 Total reward: -19.0 Training loss: 4.4647 Explore P: 0.2004 State: [  50.           97.13170248    1.82133452  379.00742903   20.        ]\n",
      "Episode: 246 Total reward: -20.0 Training loss: 3.3601 Explore P: 0.1996 State: [   25.           100.             4.45290468  2068.77013972    21.        ]\n",
      "Episode: 247 Total reward: -30.0 Training loss: 2.2422 Explore P: 0.1985 State: [   60.           100.             7.57473504  5789.06174881    31.        ]\n",
      "Episode: 248 Total reward: -19.0 Training loss: 1.4986 Explore P: 0.1978 State: [   75.           100.             4.24355693  1839.83163525    20.        ]\n",
      "Episode: 249 Total reward: -17.0 Training loss: 3.2398 Explore P: 0.1971 State: [  75.           98.83067276    1.0913015   179.93956504   18.        ]\n",
      "Episode: 250 Total reward: -23.0 Training loss: 1.4116 Explore P: 0.1963 State: [  60.           95.88347957    1.43197531  245.05221499   24.        ]\n",
      "Episode: 251 Total reward: -34.0 Training loss: 0.3358 Explore P: 0.1950 State: [  80.           96.28543647    0.90851581  120.06642066   35.        ]\n",
      "Episode: 252 Total reward: -25.0 Training loss: 0.4746 Explore P: 0.1941 State: [   55.            99.09214745     3.24491818  1085.25908525    26.        ]\n",
      "Episode: 253 Total reward: -17.0 Training loss: 0.3048 Explore P: 0.1935 State: [   45.           100.             3.99208713  1659.81010245    18.        ]\n",
      "Episode: 254 Total reward: -23.0 Training loss: 1.2730 Explore P: 0.1926 State: [   80.           100.             5.24668974  2799.57130536    24.        ]\n",
      "Episode: 255 Total reward: -36.0 Training loss: 0.4839 Explore P: 0.1913 State: [  65.          100.            3.09153346  996.1129976    37.        ]\n",
      "Episode: 256 Total reward: -17.0 Training loss: 0.5632 Explore P: 0.1907 State: [   0.           90.54287695    1.30519841  252.21650489   18.        ]\n",
      "Episode: 257 Total reward: -26.0 Training loss: 0.3980 Explore P: 0.1898 State: [  55.           97.03328957    2.10646008  480.80466116   27.        ]\n",
      "Episode: 258 Total reward: -21.0 Training loss: 1.7589 Explore P: 0.1890 State: [  55.           95.89873412    1.34776689  218.29425321   22.        ]\n",
      "Episode: 259 Total reward: -21.0 Training loss: 2.7419 Explore P: 0.1883 State: [  45.           96.12085123    1.15909914  199.50463744   22.        ]\n",
      "Episode: 260 Total reward: -21.0 Training loss: 2.4878 Explore P: 0.1875 State: [  65.           96.58695503    0.98097629  150.91472149   22.        ]\n",
      "Episode: 261 Total reward: -22.0 Training loss: 1.3999 Explore P: 0.1867 State: [  35.           95.55672838    1.60016856  313.49479126   23.        ]\n",
      "Episode: 262 Total reward: -37.0 Training loss: 0.6114 Explore P: 0.1854 State: [  50.           93.66788005    1.16331305  172.11022404   38.        ]\n",
      "Episode: 263 Total reward: -18.0 Training loss: 0.5480 Explore P: 0.1848 State: [   60.           100.             3.20113717  1062.44224189    19.        ]\n",
      "Episode: 264 Total reward: -18.0 Training loss: 6.6424 Explore P: 0.1842 State: [   50.           100.             8.96637032  8097.1685187     19.        ]\n",
      "Episode: 265 Total reward: -30.0 Training loss: 0.8687 Explore P: 0.1831 State: [  50.           94.85979979    1.50551954  264.74914114   31.        ]\n",
      "Episode: 266 Total reward: -22.0 Training loss: 1.6539 Explore P: 0.1824 State: [  50.           98.21213321    2.34762826  600.09362256   23.        ]\n",
      "Episode: 267 Total reward: -24.0 Training loss: 1.4916 Explore P: 0.1816 State: [  40.           96.97998356    2.14703945  514.47086707   25.        ]\n",
      "Episode: 268 Total reward: -35.0 Training loss: 2.8695 Explore P: 0.1804 State: [  70.           93.59415061    0.82687567  103.80262752   36.        ]\n",
      "Episode: 269 Total reward: -15.0 Training loss: 1.2062 Explore P: 0.1798 State: [   35.           100.             6.83680225  4748.71803485    16.        ]\n",
      "Episode: 270 Total reward: -40.0 Training loss: 0.5169 Explore P: 0.1785 State: [   50.           100.             3.84661961  1514.46348683    41.        ]\n",
      "Episode: 271 Total reward: -27.0 Training loss: 5.3741 Explore P: 0.1776 State: [  15.           95.77105747    2.37215704  625.94340029   28.        ]\n",
      "Episode: 272 Total reward: -20.0 Training loss: 0.4305 Explore P: 0.1769 State: [  15.           91.58775419    0.84766624  147.47567749   21.        ]\n",
      "Episode: 273 Total reward: -23.0 Training loss: 2.5834 Explore P: 0.1762 State: [  60.           97.42912844    1.58940395  296.98015423   24.        ]\n",
      "Episode: 274 Total reward: -23.0 Training loss: 0.2157 Explore P: 0.1754 State: [  55.           95.52471325    0.8304248   122.02822019   24.        ]\n",
      "Episode: 275 Total reward: -27.0 Training loss: 1.8209 Explore P: 0.1745 State: [  65.           97.22654504    1.7097732   326.88667685   28.        ]\n",
      "Episode: 276 Total reward: -32.0 Training loss: 2.1867 Explore P: 0.1734 State: [  40.           95.61774783    1.9334489   407.3047947    33.        ]\n",
      "Episode: 277 Total reward: -28.0 Training loss: 0.2468 Explore P: 0.1725 State: [   85.           100.             3.12632043  1012.32633749    29.        ]\n",
      "Episode: 278 Total reward: -21.0 Training loss: 0.6641 Explore P: 0.1719 State: [  85.          100.            2.91102809  899.44805319   22.        ]\n",
      "Episode: 279 Total reward: -23.0 Training loss: 3.8174 Explore P: 0.1711 State: [  70.           98.49748556    1.52403365  286.45185487   24.        ]\n",
      "Episode: 280 Total reward: -19.0 Training loss: 0.5957 Explore P: 0.1705 State: [  35.           96.21669318    1.43180619  263.73175533   20.        ]\n",
      "Episode: 281 Total reward: -25.0 Training loss: 0.3987 Explore P: 0.1697 State: [  30.           96.12292526    2.25608559  548.43349975   26.        ]\n",
      "Episode: 282 Total reward: -31.0 Training loss: 0.1904 Explore P: 0.1687 State: [  60.           99.11685629    2.35041198  596.07303797   32.        ]\n",
      "Episode: 283 Total reward: -28.0 Training loss: 0.2352 Explore P: 0.1678 State: [  85.           95.74007813    1.08298067  152.197881     29.        ]\n",
      "Episode: 284 Total reward: -37.0 Training loss: 8.8457 Explore P: 0.1667 State: [  65.           96.69545715    1.28488595  216.51089957   38.        ]\n",
      "Episode: 285 Total reward: -22.0 Training loss: 7.0947 Explore P: 0.1660 State: [   50.           100.             5.97475262  3659.3055452     23.        ]\n",
      "Episode: 286 Total reward: -36.0 Training loss: 0.8765 Explore P: 0.1649 State: [  65.           95.03077951    1.05754762  149.45704054   37.        ]\n",
      "Episode: 287 Total reward: -27.0 Training loss: 1.9342 Explore P: 0.1640 State: [  45.           93.90877855    1.03879569  145.54086749   28.        ]\n",
      "Episode: 288 Total reward: -22.0 Training loss: 0.5642 Explore P: 0.1633 State: [   50.           100.             4.51555599  2081.23349684    23.        ]\n",
      "Episode: 289 Total reward: -38.0 Training loss: 2.3620 Explore P: 0.1622 State: [   70.           100.             3.31332434  1130.44687014    39.        ]\n",
      "Episode: 290 Total reward: -14.0 Training loss: 0.2522 Explore P: 0.1618 State: [  20.           97.32960128    2.31482372  629.35231996   15.        ]\n",
      "Episode: 291 Total reward: -23.0 Training loss: 2.2403 Explore P: 0.1611 State: [  20.           95.3139302     2.11655597  500.32543199   24.        ]\n",
      "Episode: 292 Total reward: -14.0 Training loss: 6.1532 Explore P: 0.1606 State: [  55.           98.48522368    1.35178489  248.55804185   15.        ]\n",
      "Episode: 293 Total reward: -23.0 Training loss: 0.7135 Explore P: 0.1600 State: [   60.           100.             7.76976383  6081.69875796    24.        ]\n",
      "Episode: 294 Total reward: -18.0 Training loss: 0.1667 Explore P: 0.1594 State: [   50.           100.             3.26127707  1142.4672866     19.        ]\n",
      "Episode: 295 Total reward: -25.0 Training loss: 1.9345 Explore P: 0.1587 State: [  45.           94.49146748    1.22487706  199.13109643   26.        ]\n",
      "Episode: 296 Total reward: -23.0 Training loss: 0.2170 Explore P: 0.1580 State: [  55.           98.46884548    2.33817499  585.14267382   24.        ]\n",
      "Episode: 297 Total reward: -23.0 Training loss: 1.2444 Explore P: 0.1573 State: [  50.           94.65936288    1.13338796  163.75393175   24.        ]\n",
      "Episode: 298 Total reward: -20.0 Training loss: 1.7263 Explore P: 0.1567 State: [  55.           99.71914063    2.66387228  751.33585618   21.        ]\n",
      "Episode: 299 Total reward: -30.0 Training loss: 1.7849 Explore P: 0.1558 State: [  55.           95.40375227    1.3447576   224.64643336   31.        ]\n",
      "Episode: 300 Total reward: -18.0 Training loss: 0.4724 Explore P: 0.1553 State: [  35.           98.59177069    2.63601996  748.28593697   19.        ]\n",
      "Episode: 301 Total reward: -28.0 Training loss: 1.8717 Explore P: 0.1545 State: [  65.           99.90174221    2.90976534  879.30146986   29.        ]\n",
      "Episode: 302 Total reward: -15.0 Training loss: 2.2573 Explore P: 0.1541 State: [  35.          96.3891986    1.3150865  244.089284    16.       ]\n",
      "Episode: 303 Total reward: -20.0 Training loss: 0.2290 Explore P: 0.1535 State: [  30.           94.90784134    1.32471752  237.09328962   21.        ]\n",
      "Episode: 304 Total reward: -35.0 Training loss: 3.1295 Explore P: 0.1525 State: [  45.           93.25456237    0.81879289  109.65822252   36.        ]\n",
      "Episode: 305 Total reward: -19.0 Training loss: 0.3646 Explore P: 0.1520 State: [  35.           95.08019208    1.14040693  186.09078706   20.        ]\n",
      "Episode: 306 Total reward: -26.0 Training loss: 0.3575 Explore P: 0.1512 State: [   40.           100.             4.60313405  2179.7276004     27.        ]\n",
      "Episode: 307 Total reward: -24.0 Training loss: 0.4402 Explore P: 0.1505 State: [  60.           96.6724123     1.23457546  203.23560764   25.        ]\n",
      "Episode: 308 Total reward: -12.0 Training loss: 0.5625 Explore P: 0.1502 State: [  20.           96.4194127     1.77637597  406.67511825   13.        ]\n",
      "Episode: 309 Total reward: -20.0 Training loss: 0.2318 Explore P: 0.1496 State: [   20.           100.             4.0341615   1709.41876334    21.        ]\n",
      "Episode: 310 Total reward: -28.0 Training loss: 0.1943 Explore P: 0.1489 State: [  30.           93.08726974    1.30251743  210.43192457   29.        ]\n",
      "Episode: 311 Total reward: -16.0 Training loss: 2.3839 Explore P: 0.1484 State: [  55.           95.7259668     0.89875535  140.76869146   17.        ]\n",
      "Episode: 312 Total reward: -24.0 Training loss: 0.6174 Explore P: 0.1478 State: [  40.           96.8865206     1.5011991   288.47436802   25.        ]\n",
      "Episode: 313 Total reward: -22.0 Training loss: 0.5768 Explore P: 0.1472 State: [  65.           98.95235243    2.34065276  581.36736637   23.        ]\n",
      "Episode: 314 Total reward: -16.0 Training loss: 1.6408 Explore P: 0.1467 State: [  50.           96.41997965    1.21962595  212.87836441   17.        ]\n",
      "Episode: 315 Total reward: -16.0 Training loss: 1.4924 Explore P: 0.1463 State: [  10.           93.75297744    1.67326356  371.82687208   17.        ]\n",
      "Episode: 316 Total reward: -16.0 Training loss: 1.8948 Explore P: 0.1458 State: [  40.           93.99053273    0.80110635  127.61941971   17.        ]\n",
      "Episode: 317 Total reward: -22.0 Training loss: 0.3741 Explore P: 0.1452 State: [   75.           100.             3.77546273  1458.84150883    23.        ]\n",
      "Episode: 318 Total reward: -23.0 Training loss: 3.4898 Explore P: 0.1446 State: [  60.           95.29500012    0.87256968  121.9496567    24.        ]\n",
      "Episode: 319 Total reward: -24.0 Training loss: 2.1148 Explore P: 0.1440 State: [  55.           97.0428677     1.70659005  334.26064292   25.        ]\n",
      "Episode: 320 Total reward: -27.0 Training loss: 4.0705 Explore P: 0.1433 State: [  50.           95.64775587    0.96048471  142.47038364   28.        ]\n",
      "Episode: 321 Total reward: -18.0 Training loss: 1.0400 Explore P: 0.1428 State: [  65.           97.09605388    1.27350145  211.5091201    19.        ]\n",
      "Episode: 322 Total reward: -29.0 Training loss: 2.4749 Explore P: 0.1420 State: [  25.           95.07948939    1.31531219  259.03721306   30.        ]\n",
      "Episode: 323 Total reward: -15.0 Training loss: 0.3599 Explore P: 0.1416 State: [  45.          100.            2.21549245  582.22583805   16.        ]\n",
      "Episode: 324 Total reward: -19.0 Training loss: 2.3095 Explore P: 0.1411 State: [  60.           97.5742788     1.78285     364.72659853   20.        ]\n",
      "Episode: 325 Total reward: -30.0 Training loss: 2.1379 Explore P: 0.1403 State: [  45.           93.61226638    1.06624929  152.1305516    31.        ]\n",
      "Episode: 326 Total reward: -16.0 Training loss: 0.3553 Explore P: 0.1399 State: [  20.           93.44052776    0.97254911  180.51514767   17.        ]\n",
      "Episode: 327 Total reward: -19.0 Training loss: 2.9306 Explore P: 0.1394 State: [   75.           100.             4.63301552  2183.52957551    20.        ]\n",
      "Episode: 328 Total reward: -19.0 Training loss: 0.2267 Explore P: 0.1389 State: [  15.           95.8277991     2.20489816  572.45312251   20.        ]\n",
      "Episode: 329 Total reward: -20.0 Training loss: 3.7845 Explore P: 0.1384 State: [   35.           100.             3.26304717  1120.03212783    21.        ]\n",
      "Episode: 330 Total reward: -16.0 Training loss: 0.1853 Explore P: 0.1380 State: [  20.           94.78267891    1.51123335  311.72367248   17.        ]\n",
      "Episode: 331 Total reward: -33.0 Training loss: 0.2780 Explore P: 0.1372 State: [   80.           100.             3.38416047  1176.36427814    34.        ]\n",
      "Episode: 332 Total reward: -28.0 Training loss: 0.8905 Explore P: 0.1365 State: [  50.           95.94645618    1.64174389  311.15363154   29.        ]\n",
      "Episode: 333 Total reward: -28.0 Training loss: 1.4133 Explore P: 0.1358 State: [  30.           96.61176213    2.12513179  503.42190949   29.        ]\n",
      "Episode: 334 Total reward: -24.0 Training loss: 2.6423 Explore P: 0.1351 State: [  25.           94.44221353    1.39971666  264.67641747   25.        ]\n",
      "Episode: 335 Total reward: -29.0 Training loss: 3.3138 Explore P: 0.1344 State: [  55.           94.75328734    0.84634039  119.34251814   30.        ]\n",
      "Episode: 336 Total reward: -26.0 Training loss: 1.5182 Explore P: 0.1338 State: [  40.           98.74443526    3.09257793  993.63792751   27.        ]\n",
      "Episode: 337 Total reward: -21.0 Training loss: 5.0822 Explore P: 0.1333 State: [  15.           92.83589298    0.98173504  188.10661484   22.        ]\n",
      "Episode: 338 Total reward: -28.0 Training loss: 0.7125 Explore P: 0.1326 State: [  45.           98.55089184    2.64936262  749.70214963   29.        ]\n",
      "Episode: 339 Total reward: -24.0 Training loss: 0.7819 Explore P: 0.1320 State: [  70.           95.9412925     1.39050309  227.69176405   25.        ]\n",
      "Episode: 340 Total reward: -35.0 Training loss: 2.7876 Explore P: 0.1311 State: [  45.           97.63740242    2.60879304  718.851582     36.        ]\n",
      "Episode: 341 Total reward: -37.0 Training loss: 0.4195 Explore P: 0.1302 State: [  60.           98.49446256    2.69946536  763.88794082   38.        ]\n",
      "Episode: 342 Total reward: -17.0 Training loss: 0.9980 Explore P: 0.1298 State: [   30.           100.             3.73971828  1467.06538909    18.        ]\n",
      "Episode: 343 Total reward: -29.0 Training loss: 1.2902 Explore P: 0.1291 State: [  35.           96.2764099     2.00594458  448.71760072   30.        ]\n",
      "Episode: 344 Total reward: -21.0 Training loss: 1.0469 Explore P: 0.1286 State: [  15.           96.05770267    2.38243932  642.4854276    22.        ]\n",
      "Episode: 345 Total reward: -23.0 Training loss: 3.2036 Explore P: 0.1281 State: [  70.           97.84027439    2.17319127  508.13586885   24.        ]\n",
      "Episode: 346 Total reward: -22.0 Training loss: 0.4781 Explore P: 0.1276 State: [  15.           94.44873812    1.50652572  306.18032093   23.        ]\n",
      "Episode: 347 Total reward: -26.0 Training loss: 0.7922 Explore P: 0.1270 State: [  30.           94.59214862    1.24804141  211.25338489   27.        ]\n",
      "Episode: 348 Total reward: -18.0 Training loss: 1.0615 Explore P: 0.1265 State: [   50.           100.             4.95690905  2506.75029512    19.        ]\n",
      "Episode: 349 Total reward: -23.0 Training loss: 1.6666 Explore P: 0.1260 State: [  10.           94.84196265    2.15576498  555.18310957   24.        ]\n",
      "Episode: 350 Total reward: -20.0 Training loss: 2.5061 Explore P: 0.1256 State: [   60.           100.             4.09633957  1721.42420993    21.        ]\n",
      "Episode: 351 Total reward: -27.0 Training loss: 0.2946 Explore P: 0.1249 State: [  35.           95.14784684    1.03934541  184.48718295   28.        ]\n",
      "Episode: 352 Total reward: -22.0 Training loss: 2.4197 Explore P: 0.1244 State: [  50.           95.5437012     1.30217864  209.84206514   23.        ]\n",
      "Episode: 353 Total reward: -27.0 Training loss: 1.2741 Explore P: 0.1238 State: [   40.           100.             3.41304744  1225.5282654     28.        ]\n",
      "Episode: 354 Total reward: -17.0 Training loss: 2.3171 Explore P: 0.1234 State: [   30.           100.             4.82612119  2417.35869362    18.        ]\n",
      "Episode: 355 Total reward: -42.0 Training loss: 1.8484 Explore P: 0.1225 State: [  50.           95.20738847    1.61166863  295.42516261   43.        ]\n",
      "Episode: 356 Total reward: -14.0 Training loss: 1.7671 Explore P: 0.1222 State: [  45.           99.88212778    1.57882413  337.68355177   15.        ]\n",
      "Episode: 357 Total reward: -31.0 Training loss: 4.4604 Explore P: 0.1215 State: [  65.           98.41307542    2.64175628  729.89186104   32.        ]\n",
      "Episode: 358 Total reward: -25.0 Training loss: 1.4800 Explore P: 0.1209 State: [  40.           94.04428939    1.13617522  176.57750825   26.        ]\n",
      "Episode: 359 Total reward: -24.0 Training loss: 2.0123 Explore P: 0.1204 State: [  45.           96.71804137    1.85202328  384.56829101   25.        ]\n",
      "Episode: 360 Total reward: -24.0 Training loss: 1.0314 Explore P: 0.1198 State: [   45.           100.             3.98936703  1633.43579923    25.        ]\n",
      "Episode: 361 Total reward: -14.0 Training loss: 2.7761 Explore P: 0.1195 State: [  15.           93.54550451    1.15411007  217.11016627   15.        ]\n",
      "Episode: 362 Total reward: -21.0 Training loss: 0.4436 Explore P: 0.1191 State: [  55.           97.98902132    2.41992718  618.80994134   22.        ]\n",
      "Episode: 363 Total reward: -27.0 Training loss: 0.3840 Explore P: 0.1185 State: [   70.            99.55486173     3.13977441  1018.38072072    28.        ]\n",
      "Episode: 364 Total reward: -36.0 Training loss: 0.5147 Explore P: 0.1177 State: [   65.           100.             3.82888942  1499.62439193    37.        ]\n",
      "Episode: 365 Total reward: -29.0 Training loss: 3.2116 Explore P: 0.1171 State: [   0.           87.45542269    0.96680844  197.9427213    30.        ]\n",
      "Episode: 366 Total reward: -35.0 Training loss: 4.3035 Explore P: 0.1163 State: [  50.           96.0472763     1.28668173  213.8903766    36.        ]\n",
      "Episode: 367 Total reward: -31.0 Training loss: 0.3526 Explore P: 0.1157 State: [   65.           100.             3.51286927  1271.55629259    32.        ]\n",
      "Episode: 368 Total reward: -26.0 Training loss: 1.8397 Explore P: 0.1151 State: [  45.           94.69823189    1.29367497  210.40903338   27.        ]\n",
      "Episode: 369 Total reward: -34.0 Training loss: 0.5150 Explore P: 0.1144 State: [   65.           100.             4.22500725  1821.03975917    35.        ]\n",
      "Episode: 370 Total reward: -22.0 Training loss: 0.3373 Explore P: 0.1140 State: [  30.           96.7040613     1.94999359  433.83985246   23.        ]\n",
      "Episode: 371 Total reward: -17.0 Training loss: 0.2855 Explore P: 0.1136 State: [  20.           98.05756493    2.72505453  817.67788134   18.        ]\n",
      "Episode: 372 Total reward: -20.0 Training loss: 0.8215 Explore P: 0.1132 State: [  65.          100.            2.45213614  652.60332451   21.        ]\n",
      "Episode: 373 Total reward: -25.0 Training loss: 2.5258 Explore P: 0.1127 State: [  50.           94.28260683    1.14652875  176.08361163   26.        ]\n",
      "Episode: 374 Total reward: -23.0 Training loss: 0.8219 Explore P: 0.1122 State: [  50.           95.04222039    1.14140023  172.98333988   24.        ]\n",
      "Episode: 375 Total reward: -19.0 Training loss: 0.7236 Explore P: 0.1118 State: [  55.           95.50053897    1.29141326  213.38046063   20.        ]\n",
      "Episode: 376 Total reward: -30.0 Training loss: 1.5167 Explore P: 0.1112 State: [  50.           96.85088176    1.55505494  300.44626245   31.        ]\n",
      "Episode: 377 Total reward: -29.0 Training loss: 0.2767 Explore P: 0.1106 State: [  45.           97.10430722    1.68378278  336.26792568   30.        ]\n",
      "Episode: 378 Total reward: -37.0 Training loss: 5.4777 Explore P: 0.1099 State: [   55.            99.68139067     3.44592761  1225.45901008    38.        ]\n",
      "Episode: 379 Total reward: -24.0 Training loss: 1.0103 Explore P: 0.1094 State: [   0.           88.10425317    1.0137492   199.97982934   25.        ]\n",
      "Episode: 380 Total reward: -23.0 Training loss: 0.5749 Explore P: 0.1090 State: [   35.            99.70741643     3.39507882  1208.99511148    24.        ]\n",
      "Episode: 381 Total reward: -20.0 Training loss: 1.0123 Explore P: 0.1086 State: [  40.           96.4455457     2.22441646  534.52403219   21.        ]\n",
      "Episode: 382 Total reward: -33.0 Training loss: 1.2426 Explore P: 0.1079 State: [  60.           95.45286635    1.24498324  189.52158678   34.        ]\n",
      "Episode: 383 Total reward: -16.0 Training loss: 0.3767 Explore P: 0.1076 State: [  35.           98.12616958    2.19701727  550.99583974   17.        ]\n",
      "Episode: 384 Total reward: -62.0 Training loss: 1.2367 Explore P: 0.1064 State: [  50.           95.27304845    1.45824802  252.85308628   63.        ]\n",
      "Episode: 385 Total reward: -23.0 Training loss: 0.7517 Explore P: 0.1060 State: [  65.           94.7563758     1.08445678  151.18153934   24.        ]\n",
      "Episode: 386 Total reward: -23.0 Training loss: 0.4995 Explore P: 0.1055 State: [   70.           100.             3.4860904   1257.43044784    24.        ]\n",
      "Episode: 387 Total reward: -24.0 Training loss: 0.3200 Explore P: 0.1051 State: [  60.           95.80553599    1.22497362  188.16919278   25.        ]\n",
      "Episode: 388 Total reward: -23.0 Training loss: 1.8617 Explore P: 0.1046 State: [  25.           92.31679908    0.91279951  131.41010859   24.        ]\n",
      "Episode: 389 Total reward: -23.0 Training loss: 0.3616 Explore P: 0.1042 State: [  40.          100.            3.03509959  989.44755288   24.        ]\n",
      "Episode: 390 Total reward: -21.0 Training loss: 0.2599 Explore P: 0.1038 State: [  55.           99.82618715    2.55922436  704.09943332   22.        ]\n",
      "Episode: 391 Total reward: -30.0 Training loss: 0.6271 Explore P: 0.1032 State: [  65.           96.18578115    1.4948296   262.4295456    31.        ]\n",
      "Episode: 392 Total reward: -24.0 Training loss: 3.6442 Explore P: 0.1028 State: [  55.           97.23169575    1.57491893  288.79090628   25.        ]\n",
      "Episode: 393 Total reward: -29.0 Training loss: 0.9231 Explore P: 0.1023 State: [  75.           95.86099322    1.13441682  163.13934316   30.        ]\n",
      "Episode: 394 Total reward: -23.0 Training loss: 0.2285 Explore P: 0.1018 State: [  55.           96.84204746    1.95341112  422.84642885   24.        ]\n",
      "Episode: 395 Total reward: -21.0 Training loss: 0.9086 Explore P: 0.1014 State: [  35.           96.3337704     1.96008823  430.88147525   22.        ]\n",
      "Episode: 396 Total reward: -18.0 Training loss: 0.3874 Explore P: 0.1011 State: [  50.           96.97992982    1.36605808  249.09343932   19.        ]\n",
      "Episode: 397 Total reward: -24.0 Training loss: 0.3665 Explore P: 0.1007 State: [   50.           100.             3.25465733  1111.27606703    25.        ]\n",
      "Episode: 398 Total reward: -18.0 Training loss: 0.5703 Explore P: 0.1004 State: [   30.            99.35812098     3.53828447  1311.00767451    19.        ]\n",
      "Episode: 399 Total reward: -21.0 Training loss: 0.2138 Explore P: 0.1000 State: [  75.          100.            2.97200785  918.5987731    22.        ]\n",
      "Episode: 400 Total reward: -25.0 Training loss: 1.0912 Explore P: 0.0995 State: [   55.           100.             4.21356521  1810.34575047    26.        ]\n",
      "Episode: 401 Total reward: -32.0 Training loss: 0.7854 Explore P: 0.0990 State: [  35.           93.82490618    1.44122307  249.64656357   33.        ]\n",
      "Episode: 402 Total reward: -16.0 Training loss: 0.1923 Explore P: 0.0987 State: [   35.           100.             5.12161372  2688.11025907    17.        ]\n",
      "Episode: 403 Total reward: -20.0 Training loss: 0.7355 Explore P: 0.0983 State: [  50.           95.61567121    1.23197625  202.64186264   21.        ]\n",
      "Episode: 404 Total reward: -25.0 Training loss: 1.3272 Explore P: 0.0979 State: [  35.           96.59313962    2.27668425  560.37939434   26.        ]\n",
      "Episode: 405 Total reward: -27.0 Training loss: 0.6119 Explore P: 0.0974 State: [   45.            99.71692181     3.49893759  1261.29568857    28.        ]\n",
      "Episode: 406 Total reward: -18.0 Training loss: 0.1685 Explore P: 0.0971 State: [  90.           98.25645156    1.33445125  215.60541823   19.        ]\n",
      "Episode: 407 Total reward: -22.0 Training loss: 1.4612 Explore P: 0.0967 State: [  45.           95.3411304     1.54117015  281.36347327   23.        ]\n",
      "Episode: 408 Total reward: -41.0 Training loss: 0.5204 Explore P: 0.0960 State: [  60.           98.91126971    2.82987516  840.45551046   42.        ]\n",
      "Episode: 409 Total reward: -21.0 Training loss: 0.4411 Explore P: 0.0956 State: [  55.           95.90303196    1.11770017  168.23725601   22.        ]\n",
      "Episode: 410 Total reward: -23.0 Training loss: 1.1913 Explore P: 0.0952 State: [  50.           97.08654132    1.66673704  325.25043982   24.        ]\n",
      "Episode: 411 Total reward: -24.0 Training loss: 0.3054 Explore P: 0.0948 State: [  50.           99.72608571    1.94216633  438.203393     25.        ]\n",
      "Episode: 412 Total reward: -32.0 Training loss: 1.2547 Explore P: 0.0943 State: [   70.           100.             4.31828413  1899.57089389    33.        ]\n",
      "Episode: 413 Total reward: -20.0 Training loss: 0.2534 Explore P: 0.0940 State: [   0.           90.72476772    1.32613049  270.81323673   21.        ]\n",
      "Episode: 414 Total reward: -16.0 Training loss: 0.4286 Explore P: 0.0937 State: [  35.           95.65330222    1.22165968  228.25380063   17.        ]\n",
      "Episode: 415 Total reward: -34.0 Training loss: 0.5659 Explore P: 0.0931 State: [  55.           93.19407029    0.95143751  126.10757031   35.        ]\n",
      "Episode: 416 Total reward: -24.0 Training loss: 2.8704 Explore P: 0.0927 State: [   40.           100.             3.69972421  1414.81285125    25.        ]\n",
      "Episode: 417 Total reward: -28.0 Training loss: 0.4817 Explore P: 0.0923 State: [   65.           100.             4.08093474  1697.63162574    29.        ]\n",
      "Episode: 418 Total reward: -22.0 Training loss: 0.7475 Explore P: 0.0919 State: [  10.           94.61260182    1.98816765  474.29339992   23.        ]\n",
      "Episode: 419 Total reward: -20.0 Training loss: 2.3998 Explore P: 0.0916 State: [  65.           98.84163944    2.45827569  644.36507291   21.        ]\n",
      "Episode: 420 Total reward: -35.0 Training loss: 0.6852 Explore P: 0.0910 State: [   75.           100.             3.56416135  1308.51696403    36.        ]\n",
      "Episode: 421 Total reward: -37.0 Training loss: 0.4309 Explore P: 0.0904 State: [  45.           94.21688272    0.85428413  123.13332026   38.        ]\n",
      "Episode: 422 Total reward: -26.0 Training loss: 3.4277 Explore P: 0.0900 State: [   40.            99.40013123     3.39662548  1193.91239704    27.        ]\n",
      "Episode: 423 Total reward: -19.0 Training loss: 0.9405 Explore P: 0.0897 State: [   50.           100.             3.56554404  1320.0133052     20.        ]\n",
      "Episode: 424 Total reward: -30.0 Training loss: 0.5298 Explore P: 0.0892 State: [   80.           100.             4.85758198  2392.86078078    31.        ]\n",
      "Episode: 425 Total reward: -28.0 Training loss: 2.0992 Explore P: 0.0888 State: [  65.           95.26215625    1.10604508  158.22571553   29.        ]\n",
      "Episode: 426 Total reward: -25.0 Training loss: 1.1289 Explore P: 0.0884 State: [  40.           97.63360391    2.45340441  645.96468526   26.        ]\n",
      "Episode: 427 Total reward: -27.0 Training loss: 0.7605 Explore P: 0.0880 State: [  50.           97.22827489    2.17577929  513.81913586   28.        ]\n",
      "Episode: 428 Total reward: -14.0 Training loss: 0.4350 Explore P: 0.0877 State: [  45.           97.65980388    1.26254093  222.47540756   15.        ]\n",
      "Episode: 429 Total reward: -28.0 Training loss: 5.7044 Explore P: 0.0873 State: [  50.           97.33855038    2.07738265  472.67530198   29.        ]\n",
      "Episode: 430 Total reward: -21.0 Training loss: 0.1922 Explore P: 0.0870 State: [  50.           94.81171275    0.90029633  132.57346232   22.        ]\n",
      "Episode: 431 Total reward: -18.0 Training loss: 0.6351 Explore P: 0.0867 State: [  25.           92.89955778    0.92619751  144.58015934   19.        ]\n",
      "Episode: 432 Total reward: -22.0 Training loss: 0.2274 Explore P: 0.0864 State: [  55.           97.82960731    1.32360706  236.01772503   23.        ]\n",
      "Episode: 433 Total reward: -21.0 Training loss: 1.1424 Explore P: 0.0860 State: [   70.           100.             3.51047955  1275.48687408    22.        ]\n",
      "Episode: 434 Total reward: -51.0 Training loss: 1.2117 Explore P: 0.0853 State: [   0.           89.38641634    0.91837112  180.32039539   52.        ]\n",
      "Episode: 435 Total reward: -18.0 Training loss: 0.1998 Explore P: 0.0850 State: [   75.           100.             5.18576017  2731.06973232    19.        ]\n",
      "Episode: 436 Total reward: -15.0 Training loss: 0.1715 Explore P: 0.0848 State: [  45.           97.2912303     1.25344801  229.51479718   16.        ]\n",
      "Episode: 437 Total reward: -60.0 Training loss: 0.6721 Explore P: 0.0839 State: [  10.           94.81716505    2.03764514  508.12292154   61.        ]\n",
      "Episode: 438 Total reward: -22.0 Training loss: 0.6773 Explore P: 0.0836 State: [  85.          100.            2.83324675  838.46123833   23.        ]\n",
      "Episode: 439 Total reward: -19.0 Training loss: 0.2928 Explore P: 0.0833 State: [  90.           96.42494552    1.06756152  148.66916738   20.        ]\n",
      "Episode: 440 Total reward: -28.0 Training loss: 0.7677 Explore P: 0.0829 State: [  40.           95.08546582    1.71193914  327.97688706   29.        ]\n",
      "Episode: 441 Total reward: -22.0 Training loss: 0.3723 Explore P: 0.0826 State: [  55.           96.35683677    1.76889279  350.67566183   23.        ]\n",
      "Episode: 442 Total reward: -15.0 Training loss: 0.2260 Explore P: 0.0823 State: [  55.          100.            3.03749602  977.70855901   16.        ]\n",
      "Episode: 443 Total reward: -16.0 Training loss: 0.4153 Explore P: 0.0821 State: [  80.           98.41081583    0.97185225  144.93082398   17.        ]\n",
      "Episode: 444 Total reward: -19.0 Training loss: 0.4034 Explore P: 0.0818 State: [  75.           97.2688589     1.08080231  162.12718962   20.        ]\n",
      "Episode: 445 Total reward: -19.0 Training loss: 0.2473 Explore P: 0.0816 State: [   45.           100.             4.70716312  2265.58805647    20.        ]\n",
      "Episode: 446 Total reward: -28.0 Training loss: 0.2676 Explore P: 0.0812 State: [  85.           96.54707576    1.20585035  178.51591044   29.        ]\n",
      "Episode: 447 Total reward: -26.0 Training loss: 0.2374 Explore P: 0.0808 State: [  35.           94.18565156    1.2287236   205.66100533   27.        ]\n",
      "Episode: 448 Total reward: -16.0 Training loss: 2.2524 Explore P: 0.0806 State: [  30.           96.97127963    2.05951679  494.59658471   17.        ]\n",
      "Episode: 449 Total reward: -24.0 Training loss: 0.3704 Explore P: 0.0802 State: [  25.           94.49365124    1.37558214  258.93907115   25.        ]\n",
      "Episode: 450 Total reward: -18.0 Training loss: 0.6417 Explore P: 0.0800 State: [  7.50000000e+01   1.00000000e+02   1.41335578e+01   2.00257354e+04\n",
      "   1.90000000e+01]\n",
      "Episode: 451 Total reward: -22.0 Training loss: 1.3609 Explore P: 0.0797 State: [  85.           97.22811312    1.54456128  273.31043451   23.        ]\n",
      "Episode: 452 Total reward: -16.0 Training loss: 0.2900 Explore P: 0.0794 State: [  30.           98.36181651    2.56314803  734.44674803   17.        ]\n",
      "Episode: 453 Total reward: -22.0 Training loss: 1.8955 Explore P: 0.0791 State: [  45.           93.11533523    0.85085309  119.06786191   23.        ]\n",
      "Episode: 454 Total reward: -23.0 Training loss: 0.1371 Explore P: 0.0788 State: [  70.           98.6371297     2.47079007  644.43935046   24.        ]\n",
      "Episode: 455 Total reward: -27.0 Training loss: 0.6214 Explore P: 0.0785 State: [  75.           97.05232276    1.42782166  238.58023552   28.        ]\n",
      "Episode: 456 Total reward: -15.0 Training loss: 0.3783 Explore P: 0.0782 State: [  45.           96.16060378    1.1694232   199.04020578   16.        ]\n",
      "Episode: 457 Total reward: -23.0 Training loss: 1.2891 Explore P: 0.0779 State: [   45.            98.64583858     3.12632889  1012.36772221    24.        ]\n",
      "Episode: 458 Total reward: -12.0 Training loss: 0.2769 Explore P: 0.0778 State: [   35.           100.             8.49040187  7293.12467122    13.        ]\n",
      "Episode: 459 Total reward: -31.0 Training loss: 0.6934 Explore P: 0.0774 State: [  60.           96.42682512    1.88430148  388.78464965   32.        ]\n",
      "Episode: 460 Total reward: -28.0 Training loss: 0.3787 Explore P: 0.0770 State: [  55.           95.69729188    1.48236401  259.1429879    29.        ]\n",
      "Episode: 461 Total reward: -20.0 Training loss: 1.5790 Explore P: 0.0767 State: [  35.           97.21819957    1.99630724  449.30928301   21.        ]\n",
      "Episode: 462 Total reward: -18.0 Training loss: 0.8050 Explore P: 0.0765 State: [  25.           94.53377185    1.09945189  211.46934458   19.        ]\n",
      "Episode: 463 Total reward: -12.0 Training loss: 0.5885 Explore P: 0.0763 State: [   30.           100.             5.55955333  3179.91082357    13.        ]\n",
      "Episode: 464 Total reward: -26.0 Training loss: 0.4807 Explore P: 0.0760 State: [  70.           96.23057384    1.55479068  276.34766881   27.        ]\n",
      "Episode: 465 Total reward: -12.0 Training loss: 0.4238 Explore P: 0.0758 State: [   30.           100.             4.90120972  2483.10795617    13.        ]\n",
      "Episode: 466 Total reward: -18.0 Training loss: 0.9784 Explore P: 0.0756 State: [  30.           98.69432664    2.63246648  769.68434525   19.        ]\n",
      "Episode: 467 Total reward: -15.0 Training loss: 2.3856 Explore P: 0.0754 State: [  40.           97.03468941    1.50240031  283.53855606   16.        ]\n",
      "Episode: 468 Total reward: -21.0 Training loss: 0.7560 Explore P: 0.0751 State: [   55.           100.             3.96110182  1610.07561448    22.        ]\n",
      "Episode: 469 Total reward: -25.0 Training loss: 0.1562 Explore P: 0.0748 State: [  45.           94.62974722    1.30438781  204.58323306   26.        ]\n",
      "Episode: 470 Total reward: -27.0 Training loss: 0.2238 Explore P: 0.0744 State: [   50.           100.             3.56066737  1315.15002513    28.        ]\n",
      "Episode: 471 Total reward: -24.0 Training loss: 0.1418 Explore P: 0.0741 State: [  75.           95.76576059    0.91614799  127.47016561   25.        ]\n",
      "Episode: 472 Total reward: -31.0 Training loss: 0.7276 Explore P: 0.0737 State: [  35.           93.8667089     1.58575707  286.14246261   32.        ]\n",
      "Episode: 473 Total reward: -16.0 Training loss: 0.9770 Explore P: 0.0735 State: [  70.           99.99922684    1.57844529  303.22691104   17.        ]\n",
      "Episode: 474 Total reward: -21.0 Training loss: 0.1630 Explore P: 0.0733 State: [  95.          100.            2.70844819  768.44088686   22.        ]\n",
      "Episode: 475 Total reward: -23.0 Training loss: 0.4157 Explore P: 0.0730 State: [  30.           97.2736479     2.66508019  765.47646414   24.        ]\n",
      "Episode: 476 Total reward: -23.0 Training loss: 0.4122 Explore P: 0.0727 State: [  10.           92.89672803    1.61893399  340.09370763   24.        ]\n",
      "Episode: 477 Total reward: -13.0 Training loss: 0.5660 Explore P: 0.0725 State: [  25.           94.37704001    0.97158107  190.85055245   14.        ]\n",
      "Episode: 478 Total reward: -12.0 Training loss: 0.2409 Explore P: 0.0724 State: [  40.           95.88899067    0.81060069  147.77497579   13.        ]\n",
      "Episode: 479 Total reward: -173.0 Training loss: 1.0924 Explore P: 0.0702 State: [   45.           100.             3.03605756  1001.30876596   174.        ]\n",
      "Episode: 480 Total reward: -20.0 Training loss: 0.7660 Explore P: 0.0700 State: [  55.           94.64394043    1.11177601  165.89464804   21.        ]\n",
      "Episode: 481 Total reward: -21.0 Training loss: 0.1679 Explore P: 0.0697 State: [  60.           95.10531489    0.84341646  124.46761832   22.        ]\n",
      "Episode: 482 Total reward: -33.0 Training loss: 0.3418 Explore P: 0.0694 State: [  55.           94.09890511    1.15592365  166.66007032   34.        ]\n",
      "Episode: 483 Total reward: -17.0 Training loss: 0.6424 Explore P: 0.0692 State: [  50.           97.24559019    1.47849818  268.86375995   18.        ]\n",
      "Episode: 484 Total reward: -24.0 Training loss: 0.0926 Explore P: 0.0689 State: [  50.           98.10391544    2.57862991  704.3332086    25.        ]\n",
      "Episode: 485 Total reward: -25.0 Training loss: 2.2216 Explore P: 0.0686 State: [  75.           98.8158942     2.578231    697.80143827   26.        ]\n",
      "Episode: 486 Total reward: -21.0 Training loss: 0.4210 Explore P: 0.0683 State: [   55.           100.             4.00921456  1648.47162555    22.        ]\n",
      "Episode: 487 Total reward: -21.0 Training loss: 1.6435 Explore P: 0.0681 State: [  95.           94.96247539    0.8220318   102.41352247   22.        ]\n",
      "Episode: 488 Total reward: -17.0 Training loss: 0.5287 Explore P: 0.0679 State: [   25.           100.             4.21751639  1850.78018399    18.        ]\n",
      "Episode: 489 Total reward: -25.0 Training loss: 0.3766 Explore P: 0.0676 State: [   85.           100.             3.99022658  1624.71530002    26.        ]\n",
      "Episode: 490 Total reward: -18.0 Training loss: 0.1579 Explore P: 0.0674 State: [  95.           97.55236315    1.08863242  153.33747528   19.        ]\n",
      "Episode: 491 Total reward: -20.0 Training loss: 0.2233 Explore P: 0.0672 State: [  85.           96.0610529     1.14332732  165.25908067   21.        ]\n",
      "Episode: 492 Total reward: -19.0 Training loss: 0.4286 Explore P: 0.0669 State: [  60.           96.87391763    1.01092157  156.50807089   20.        ]\n",
      "Episode: 493 Total reward: -23.0 Training loss: 0.2886 Explore P: 0.0667 State: [  85.           95.54400024    0.84956959  108.02395318   24.        ]\n",
      "Episode: 494 Total reward: -21.0 Training loss: 0.4715 Explore P: 0.0664 State: [  80.           98.34059083    1.41210217  237.05936931   22.        ]\n",
      "Episode: 495 Total reward: -25.0 Training loss: 0.4247 Explore P: 0.0662 State: [  70.           98.25503058    2.20014783  522.69761772   26.        ]\n",
      "Episode: 496 Total reward: -25.0 Training loss: 0.1329 Explore P: 0.0659 State: [  65.           95.19455703    1.19260484  180.05579036   26.        ]\n",
      "Episode: 497 Total reward: -27.0 Training loss: 0.1887 Explore P: 0.0656 State: [  45.           96.74209826    2.04079414  457.40332752   28.        ]\n",
      "Episode: 498 Total reward: -15.0 Training loss: 0.2690 Explore P: 0.0654 State: [   30.           100.             6.66468686  4529.96447798    16.        ]\n",
      "Episode: 499 Total reward: -19.0 Training loss: 0.2143 Explore P: 0.0652 State: [   95.           100.             3.55868753  1302.37450487    20.        ]\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver()\n",
    "rewards_list = []\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 0\n",
    "    for ep in range(1, train_episodes):\n",
    "        total_reward = 0\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            # Uncomment this next line to watch the training\n",
    "            env.render() \n",
    "            \n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from Q-network\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                action = np.argmax(Qs)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "            total_reward += reward\n",
    "            \n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Training loss: {:.4f}'.format(loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p),\n",
    "                      'State: {}'.format(next_state))\n",
    "                \n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                \n",
    "                \n",
    "                rewards_list.append((ep, total_reward))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            # Train network\n",
    "            target_Qs = sess.run(mainQN.output, feed_dict={mainQN.inputs_: next_states})\n",
    "            \n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            target_Qs[episode_ends] = (0, 0, 0)\n",
    "            \n",
    "            targets = rewards + gamma * np.max(target_Qs, axis=1)\n",
    "\n",
    "            loss, _ = sess.run([mainQN.loss, mainQN.opt],\n",
    "                                feed_dict={mainQN.inputs_: states,\n",
    "                                           mainQN.targetQs_: targets,\n",
    "                                           mainQN.actions_: actions})\n",
    "        \n",
    "    saver.save(sess, \"checkpoints/cartpole.ckpt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xf745fd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEKCAYAAADTgGjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bb2da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, rews = np.array(rewards_list).T\n",
    "smoothed_rews = running_mean(rews, 10)\n",
    "plt.plot(eps[-len(smoothed_rews):], smoothed_rews)\n",
    "plt.plot(eps, rews, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e+01   3.76084941e+01   2.13854551e-11   7.28550474e+01\n",
      "   1.00000000e+00] -1.0 False {}\n",
      "[  1.50000000e+01   3.85212354e+01   5.10282971e-11   7.17556884e+01\n",
      "   2.00000000e+00] -1.0 False {}\n",
      "[  2.00000000e+01   3.97382237e+01   9.92878922e-11   7.03327526e+01\n",
      "   3.00000000e+00] -1.0 False {}\n",
      "[  2.50000000e+01   4.12594590e+01   1.91307664e-10   6.86197194e+01\n",
      "   4.00000000e+00] -1.0 False {}\n",
      "[  3.00000000e+01   4.30849415e+01   3.96047134e-10   6.66547622e+01\n",
      "   5.00000000e+00] -1.0 False {}\n",
      "[  3.50000000e+01   4.52146710e+01   9.25192805e-10   6.44788646e+01\n",
      "   6.00000000e+00] -1.0 False {}\n",
      "[  4.00000000e+01   4.76486476e+01   2.50535212e-09   6.21340041e+01\n",
      "   7.00000000e+00] -1.0 False {}\n",
      "[  4.50000000e+01   5.03868712e+01   7.92507176e-09   5.96615305e+01\n",
      "   8.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+01   5.34293420e+01   2.91348177e-08   5.71008197e+01\n",
      "   9.00000000e+00] -1.0 False {}\n",
      "[  5.50000000e+01   5.67760599e+01   1.23167717e-07   5.44882480e+01\n",
      "   1.00000000e+01] -1.0 False {}\n",
      "[  6.00000000e+01   6.04270254e+01   5.91896532e-07   5.18564899e+01\n",
      "   1.10000000e+01] -1.0 False {}\n",
      "[  6.50000000e+01   6.43822405e+01   3.19817115e-06   4.92341169e+01\n",
      "   1.20000000e+01] -1.0 False {}\n",
      "[  7.00000000e+01   6.86417188e+01   1.92313996e-05   4.66454501e+01\n",
      "   1.30000000e+01] -1.0 False {}\n",
      "[  7.50000000e+01   7.32055523e+01   1.27448409e-04   4.41105940e+01\n",
      "   1.40000000e+01] -1.0 False {}\n",
      "[  8.00000000e+01   7.80744276e+01   9.22123753e-04   4.16455021e+01\n",
      "   1.50000000e+01] -1.0 False {}\n",
      "[  8.50000000e+01   8.32538472e+01   7.21936074e-03   3.92653770e+01\n",
      "   1.60000000e+01] -1.0 False {}\n",
      "[  9.00000000e+01   8.87910302e+01   6.07356470e-02   3.73149867e+01\n",
      "   1.70000000e+01] -1.0 False {}\n",
      "[ 95.          95.12517748   0.55345291  65.18924897  18.        ] -1.0 False {}\n",
      "[   90.           100.             6.30682717  4010.49203447    19.        ] -1 True {}\n",
      "[  1.00000000e+01   3.83231337e+01   4.84844629e-11   1.14831951e+02\n",
      "   2.00000000e+00] -1.0 False {}\n",
      "[  1.50000000e+01   3.96462675e+01   9.19104296e-11   1.12354330e+02\n",
      "   3.00000000e+00] -1.0 False {}\n",
      "[  2.00000000e+01   4.14104458e+01   1.79565678e-10   1.09187994e+02\n",
      "   4.00000000e+00] -1.0 False {}\n",
      "[  2.50000000e+01   4.36156687e+01   4.01125402e-10   1.05435776e+02\n",
      "   5.00000000e+00] -1.0 False {}\n",
      "[  3.00000000e+01   4.62619361e+01   1.09706881e-09   1.01210408e+02\n",
      "   6.00000000e+00] -1.0 False {}\n",
      "[  3.50000000e+01   4.93492482e+01   3.78868742e-09   9.66273353e+01\n",
      "   7.00000000e+00] -1.0 False {}\n",
      "[  4.00000000e+01   5.28776048e+01   1.64703221e-08   9.17985055e+01\n",
      "   8.00000000e+00] -1.0 False {}\n",
      "[  4.50000000e+01   5.68470061e+01   8.83973175e-08   8.68275277e+01\n",
      "   9.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+01   6.12574525e+01   5.73191744e-07   8.18063825e+01\n",
      "   1.00000000e+01] -1.0 False {}\n",
      "[  5.50000000e+01   6.61089473e+01   4.40342087e-06   7.68135995e+01\n",
      "   1.10000000e+01] -1.0 False {}\n",
      "[  6.00000000e+01   7.14015216e+01   3.93739261e-05   7.19136681e+01\n",
      "   1.20000000e+01] -1.0 False {}\n",
      "[  6.50000000e+01   7.71355041e+01   4.02998594e-04   6.71572456e+01\n",
      "   1.30000000e+01] -1.0 False {}\n",
      "[  7.00000000e+01   8.33147748e+01   4.64663046e-03   6.25821373e+01\n",
      "   1.40000000e+01] -1.0 False {}\n",
      "[  7.50000000e+01   8.99899503e+01   5.95068331e-02   5.85327072e+01\n",
      "   1.50000000e+01] -1.0 False {}\n",
      "[  80.           97.89589676    0.84923318  125.6995396    16.        ] -1 True {}\n",
      "[  5.00000000e+00   3.74641044e+01   4.27709102e-11   1.09360875e+02\n",
      "   2.00000000e+00] -1.0 False {}\n",
      "[  1.00000000e+01   3.83923131e+01   7.02069880e-11   1.07680299e+02\n",
      "   3.00000000e+00] -1.0 False {}\n",
      "[  1.50000000e+01   3.97846262e+01   1.15263953e-10   1.05239718e+02\n",
      "   4.00000000e+00] -1.0 False {}\n",
      "[  2.00000000e+01   4.16410436e+01   2.09566942e-10   1.02127370e+02\n",
      "   5.00000000e+00] -1.0 False {}\n",
      "[  2.50000000e+01   4.39615654e+01   4.59484246e-10   9.84488159e+01\n",
      "   6.00000000e+00] -1.0 False {}\n",
      "[  3.00000000e+01   4.67461916e+01   1.29108687e-09   9.43190059e+01\n",
      "   7.00000000e+00] -1.0 False {}\n",
      "[  3.50000000e+01   4.99949221e+01   4.73031054e-09   8.98547356e+01\n",
      "   8.00000000e+00] -1.0 False {}\n",
      "[  4.00000000e+01   5.37077570e+01   2.22019040e-08   8.51682201e+01\n",
      "   9.00000000e+00] -1.0 False {}\n",
      "[  4.50000000e+01   5.78846964e+01   1.29814172e-07   8.03622325e+01\n",
      "   1.00000000e+01] -1.0 False {}\n",
      "[  5.00000000e+01   6.25257409e+01   9.22156171e-07   7.55269290e+01\n",
      "   1.10000000e+01] -1.0 False {}\n",
      "[  5.50000000e+01   6.76308967e+01   7.79276284e-06   7.07382354e+01\n",
      "   1.20000000e+01] -1.0 False {}\n",
      "[  6.00000000e+01   7.32002259e+01   7.68764326e-05   6.60574957e+01\n",
      "   1.30000000e+01] -1.0 False {}\n",
      "[  6.50000000e+01   7.92344523e+01   8.69729023e-04   6.15317862e+01\n",
      "   1.40000000e+01] -1.0 False {}\n",
      "[  7.00000000e+01   8.57430081e+01   1.10947861e-02   5.72023277e+01\n",
      "   1.50000000e+01] -1.0 False {}\n",
      "[ 75.          92.86207783   0.15750432  55.46349681  16.        ] -1.0 False {}\n",
      "[  80.          100.            2.57198845  710.75619932   17.        ] -1 True {}\n",
      "[  1.00000000e+01   3.83320005e+01   4.85274359e-11   1.22387136e+02\n",
      "   2.00000000e+00] -1.0 False {}\n",
      "[  1.50000000e+01   3.96640011e+01   9.21591449e-11   1.19729396e+02\n",
      "   3.00000000e+00] -1.0 False {}\n",
      "[  2.00000000e+01   4.14400018e+01   1.80639857e-10   1.16333802e+02\n",
      "   4.00000000e+00] -1.0 False {}\n",
      "[  2.50000000e+01   4.36600026e+01   4.05648476e-10   1.12311267e+02\n",
      "   5.00000000e+00] -1.0 False {}\n",
      "[  3.00000000e+01   4.63240037e+01   1.11767530e-09   1.07783268e+02\n",
      "   6.00000000e+00] -1.0 False {}\n",
      "[  3.50000000e+01   4.94320049e+01   3.89530898e-09   1.02874089e+02\n",
      "   7.00000000e+00] -1.0 False {}\n",
      "[  4.00000000e+01   5.29840064e+01   1.71095524e-08   9.77041007e+01\n",
      "   8.00000000e+00] -1.0 False {}\n",
      "[  4.50000000e+01   5.69800080e+01   9.28569585e-08   9.23845590e+01\n",
      "   9.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+01   6.14200104e+01   6.09247772e-07   8.70140829e+01\n",
      "   1.00000000e+01] -1.0 False {}\n",
      "[  5.50000000e+01   6.63040171e+01   4.73837505e-06   8.16767221e+01\n",
      "   1.10000000e+01] -1.0 False {}\n",
      "[  6.00000000e+01   7.16320621e+01   4.29105420e-05   7.64413573e+01\n",
      "   1.20000000e+01] -1.0 False {}\n",
      "[  6.50000000e+01   7.74045093e+01   4.44924710e-04   7.13619410e+01\n",
      "   1.30000000e+01] -1.0 False {}\n",
      "[  7.00000000e+01   8.36257094e+01   5.19764053e-03   6.64786989e+01\n",
      "   1.40000000e+01] -1.0 False {}\n",
      "[  7.50000000e+01   9.03531641e+01   6.74521040e-02   6.22306011e+01\n",
      "   1.50000000e+01] -1.0 False {}\n",
      "[  80.           98.43511519    0.97794824  152.44026433   16.        ] -1 True {}\n",
      "[  1.00000000e+01   3.87948091e+01   5.08664245e-11   1.82524722e+02\n",
      "   2.00000000e+00] -1.0 False {}\n",
      "[  1.50000000e+01   4.05896183e+01   1.06685663e-10   1.77244719e+02\n",
      "   3.00000000e+00] -1.0 False {}\n",
      "[  2.00000000e+01   4.29826971e+01   2.50791671e-10   1.70593539e+02\n",
      "   4.00000000e+00] -1.0 False {}\n",
      "[  2.50000000e+01   4.59740457e+01   7.52676774e-10   1.62849422e+02\n",
      "   5.00000000e+00] -1.0 False {}\n",
      "[  3.00000000e+01   4.95636639e+01   3.07850471e-09   1.54304043e+02\n",
      "   6.00000000e+00] -1.0 False {}\n",
      "[  3.50000000e+01   5.37515519e+01   1.71859512e-08   1.45240540e+02\n",
      "   7.00000000e+00] -1.0 False {}\n",
      "[  4.00000000e+01   5.85377097e+01   1.27103666e-07   1.35916886e+02\n",
      "   8.00000000e+00] -1.0 False {}\n",
      "[  4.50000000e+01   6.39221383e+01   1.20478803e-06   1.26555360e+02\n",
      "   9.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+01   6.99048496e+01   1.42121673e-05   1.17337682e+02\n",
      "   1.00000000e+01] -1.0 False {}\n",
      "[  5.50000000e+01   7.64860196e+01   2.03122030e-04   1.08404527e+02\n",
      "   1.10000000e+01] -1.0 False {}\n",
      "[  5.50000000e+01   8.30704152e+01   3.42884770e-03   1.00526294e+02\n",
      "   1.20000000e+01] -1.0 False {}\n",
      "[  5.50000000e+01   8.97044741e+01   5.30920392e-02   9.37667048e+01\n",
      "   1.30000000e+01] -1.0 False {}\n",
      "[  60.           97.64282017    0.75910959  143.6787043    14.        ] -1.0 False {}\n",
      "[  5.50000000e+01   1.00000000e+02   1.56879569e+01   2.46952285e+04\n",
      "   1.50000000e+01] -1 True {}\n",
      "[  1.00000000e+01   3.80675356e+01   4.72741936e-11   1.09109113e+02\n",
      "   2.00000000e+00] -1.0 False {}\n",
      "[  1.50000000e+01   3.91350712e+01   8.51643424e-11   1.07197550e+02\n",
      "   3.00000000e+00] -1.0 False {}\n",
      "[  2.00000000e+01   4.05584520e+01   1.52035028e-10   1.04735103e+02\n",
      "   4.00000000e+00] -1.0 False {}\n",
      "[  2.50000000e+01   4.23376780e+01   2.93800292e-10   1.01788147e+02\n",
      "   5.00000000e+00] -1.0 False {}\n",
      "[  3.00000000e+01   4.44727492e+01   6.53008709e-10   9.84312594e+01\n",
      "   6.00000000e+00] -1.0 False {}\n",
      "[  3.50000000e+01   4.69636657e+01   1.73421178e-09   9.47431044e+01\n",
      "   7.00000000e+00] -1.0 False {}\n",
      "[  4.00000000e+01   4.98104273e+01   5.57269660e-09   9.08026201e+01\n",
      "   8.00000000e+00] -1.0 False {}\n",
      "[  4.50000000e+01   5.30130341e+01   2.15177694e-08   8.66857722e+01\n",
      "   9.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+01   5.65714862e+01   9.83417728e-08   8.24630352e+01\n",
      "   1.00000000e+01] -1.0 False {}\n",
      "[  5.50000000e+01   6.04857840e+01   5.23630167e-07   7.81976451e+01\n",
      "   1.10000000e+01] -1.0 False {}\n",
      "[  6.00000000e+01   6.47559296e+01   3.20204875e-06   7.39445822e+01\n",
      "   1.20000000e+01] -1.0 False {}\n",
      "[  6.50000000e+01   6.93819394e+01   2.21958049e-05   6.97501784e+01\n",
      "   1.30000000e+01] -1.0 False {}\n",
      "[  7.00000000e+01   7.43639446e+01   1.72269649e-04   6.56521675e+01\n",
      "   1.40000000e+01] -1.0 False {}\n",
      "[  7.50000000e+01   7.97031021e+01   1.47949977e-03   6.16797747e+01\n",
      "   1.50000000e+01] -1.0 False {}\n",
      "[  8.00000000e+01   8.54105305e+01   1.39052179e-02   5.78673698e+01\n",
      "   1.60000000e+01] -1.0 False {}\n",
      "[ 85.          91.60190127   0.1420023   56.12625241  17.        ] -1.0 False {}\n",
      "[  90.           99.63100037    1.62388546  313.51302826   18.        ] -1 True {}\n",
      "[  1.00000000e+01   3.81178814e+01   4.75082821e-11   1.13457921e+02\n",
      "   2.00000000e+00] -1.0 False {}\n",
      "[  1.50000000e+01   3.92357627e+01   8.64306571e-11   1.11379052e+02\n",
      "   3.00000000e+00] -1.0 False {}\n",
      "[  2.00000000e+01   4.07262712e+01   1.56967945e-10   1.08705300e+02\n",
      "   4.00000000e+00] -1.0 False {}\n",
      "[  2.50000000e+01   4.25894069e+01   3.11796179e-10   1.05511715e+02\n",
      "   5.00000000e+00] -1.0 False {}\n",
      "[  3.00000000e+01   4.48251696e+01   7.21156981e-10   1.01882211e+02\n",
      "   6.00000000e+00] -1.0 False {}\n",
      "[  3.50000000e+01   4.74335595e+01   2.01619283e-09   9.79047845e+01\n",
      "   7.00000000e+00] -1.0 False {}\n",
      "[  4.00000000e+01   5.04145765e+01   6.88029189e-09   9.36671387e+01\n",
      "   8.00000000e+00] -1.0 False {}\n",
      "[  4.50000000e+01   5.37682206e+01   2.83823335e-08   8.92530272e+01\n",
      "   9.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+01   5.74944920e+01   1.39190274e-07   8.47394780e+01\n",
      "   1.00000000e+01] -1.0 False {}\n",
      "[  5.50000000e+01   6.15933911e+01   7.98123675e-07   8.01949382e+01\n",
      "   1.10000000e+01] -1.0 False {}\n",
      "[  6.00000000e+01   6.60649219e+01   5.27143926e-06   7.56782687e+01\n",
      "   1.20000000e+01] -1.0 False {}\n",
      "[  6.50000000e+01   7.09091140e+01   3.95568601e-05   7.12384431e+01\n",
      "   1.30000000e+01] -1.0 False {}\n",
      "[  7.00000000e+01   7.61262267e+01   3.32888431e-04   6.69146833e+01\n",
      "   1.40000000e+01] -1.0 False {}\n",
      "[  7.50000000e+01   8.17187362e+01   3.10272167e-03   6.27367146e+01\n",
      "   1.50000000e+01] -1.0 False {}\n",
      "[  8.00000000e+01   8.77124404e+01   3.16701944e-02   5.88086142e+01\n",
      "   1.60000000e+01] -1.0 False {}\n",
      "[ 85.         94.4002254   0.3531239  67.1563755  17.       ] -1.0 False {}\n",
      "[   80.           100.             4.7145652   2274.36229429    18.        ] -1 True {}\n",
      "[  1.50000000e+01   3.88897427e+01   5.34619262e-11   1.00467222e+02\n",
      "   2.00000000e+00] -1.0 False {}\n",
      "[  2.00000000e+01   4.04015368e+01   1.12168845e-10   9.80123410e+01\n",
      "   3.00000000e+00] -1.0 False {}\n",
      "[  2.50000000e+01   4.22912795e+01   2.42707663e-10   9.50826134e+01\n",
      "   4.00000000e+00] -1.0 False {}\n",
      "[  3.00000000e+01   4.45589707e+01   5.93358336e-10   9.17562097e+01\n",
      "   5.00000000e+00] -1.0 False {}\n",
      "[  3.50000000e+01   4.72046104e+01   1.72340937e-09   8.81148979e+01\n",
      "   6.00000000e+00] -1.0 False {}\n",
      "[  4.00000000e+01   5.02281987e+01   6.05783456e-09   8.42399378e+01\n",
      "   7.00000000e+00] -1.0 False {}\n",
      "[  4.50000000e+01   5.36297355e+01   2.56675918e-08   8.02086724e+01\n",
      "   8.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+01   5.74092209e+01   1.29290353e-07   7.60919701e+01\n",
      "   9.00000000e+00] -1.0 False {}\n",
      "[  5.50000000e+01   6.15666556e+01   7.62166127e-07   7.19525424e+01\n",
      "   1.00000000e+01] -1.0 False {}\n",
      "[  6.00000000e+01   6.61020431e+01   5.18061775e-06   6.78440646e+01\n",
      "   1.10000000e+01] -1.0 False {}\n",
      "[  6.50000000e+01   7.10154141e+01   4.00428006e-05   6.38109537e+01\n",
      "   1.20000000e+01] -1.0 False {}\n",
      "[  7.00000000e+01   7.63070409e+01   3.47313860e-04   5.98885490e+01\n",
      "   1.30000000e+01] -1.0 False {}\n",
      "[  7.50000000e+01   8.19796065e+01   3.33769370e-03   5.61035454e+01\n",
      "   1.40000000e+01] -1.0 False {}\n",
      "[  8.00000000e+01   8.80619162e+01   3.51331419e-02   5.25801663e+01\n",
      "   1.50000000e+01] -1.0 False {}\n",
      "[ 85.          94.89143864   0.40439737  65.15331357  16.        ] -1.0 False {}\n",
      "[   80.           100.             5.66686803  3257.66421388    17.        ] -1 True {}\n",
      "[  1.00000000e+01   3.85742529e+01   4.97279181e-11   1.20176691e+02\n",
      "   2.00000000e+00] -1.0 False {}\n",
      "[  1.50000000e+01   4.01485059e+01   9.93688939e-11   1.17110821e+02\n",
      "   3.00000000e+00] -1.0 False {}\n",
      "[  2.00000000e+01   4.22475098e+01   2.13626939e-10   1.13222831e+02\n",
      "   4.00000000e+00] -1.0 False {}\n",
      "[  2.50000000e+01   4.48712647e+01   5.56389481e-10   1.08658865e+02\n",
      "   5.00000000e+00] -1.0 False {}\n",
      "[  3.00000000e+01   4.80197706e+01   1.88231768e-09   1.03575343e+02\n",
      "   6.00000000e+00] -1.0 False {}\n",
      "[  3.50000000e+01   5.16930275e+01   8.41182963e-09   9.81279354e+01\n",
      "   7.00000000e+00] -1.0 False {}\n",
      "[  4.00000000e+01   5.58910354e+01   4.87458862e-08   9.24626500e+01\n",
      "   8.00000000e+00] -1.0 False {}\n",
      "[  4.50000000e+01   6.06137946e+01   3.56223594e-07   8.67095727e+01\n",
      "   9.00000000e+00] -1.0 False {}\n",
      "[  5.00000000e+01   6.58613076e+01   3.19870896e-06   8.09792726e+01\n",
      "   1.00000000e+01] -1.0 False {}\n",
      "[  5.50000000e+01   7.16336028e+01   3.44840652e-05   7.53615027e+01\n",
      "   1.10000000e+01] -1.0 False {}\n",
      "[  6.00000000e+01   7.79310514e+01   4.36767797e-04   6.99254693e+01\n",
      "   1.20000000e+01] -1.0 False {}\n",
      "[  6.50000000e+01   8.47591806e+01   6.36648808e-03   6.47221944e+01\n",
      "   1.30000000e+01] -1.0 False {}\n",
      "[ 70.          92.21058461   0.10489027  60.8176528   14.        ] -1.0 False {}\n",
      "[  75.          100.            1.98161521  447.80442853   15.        ] -1 True {}\n"
     ]
    }
   ],
   "source": [
    "test_episodes = 10\n",
    "test_max_steps = 400\n",
    "env.reset()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    for ep in range(1, test_episodes):\n",
    "        t = 0\n",
    "        while t < test_max_steps:\n",
    "            env.render() \n",
    "            \n",
    "            # Get action from Q-network\n",
    "            feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "            Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "            action = np.argmax(Qs)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            print(next_state, reward, done, info)\n",
    "            \n",
    "            if done:\n",
    "                t = test_max_steps\n",
    "                env.reset()\n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                state = next_state\n",
    "                t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
